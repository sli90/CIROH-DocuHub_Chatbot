{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7be2e6e8",
   "metadata": {},
   "source": [
    "# **CIROH AI Bot - Database Population and Embedding Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf991d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from database import DatabaseManager\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import openai\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f44220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\")\n",
    "\n",
    "BASE_URL = \"https://docs.ciroh.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aa56d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the manager\n",
    "db_manager = DatabaseManager()\n",
    "\n",
    "def initialize_schema(schema_file='schema.sql'):\n",
    "    \"\"\"\n",
    "    Checks if the core tables exist in the configured schema.\n",
    "    If not, executes the provided SQL script to initialize the database.\n",
    "    \"\"\"\n",
    "    # Tables to verify existence\n",
    "    required_tables = ['TBLArtifactTypes', 'TBLArtifacts', 'TBLChunkTypes', 'TBLChunks']\n",
    "    \n",
    "    # Query to check existing tables in the current search_path\n",
    "    check_query = \"\"\"\n",
    "    SELECT table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = %s;\n",
    "    \"\"\"\n",
    "    \n",
    "    with db_manager as db:\n",
    "        print(f\"Checking schema: {db.schema}...\")\n",
    "        existing_tables = db.execute_query(check_query, (db.schema,), fetch=True)\n",
    "        existing_table_names = [t['table_name'].lower() for t in existing_tables]\n",
    "\n",
    "        # Determine if any required table is missing\n",
    "        missing_tables = [t.lower() for t in required_tables if t.lower() not in existing_table_names]\n",
    "        \n",
    "        if missing_tables:\n",
    "            print(f\"Missing tables detected: {missing_tables}. Initializing schema...\")\n",
    "            \n",
    "            if not os.path.exists(schema_file):\n",
    "                print(f\"Error: {schema_file} not found.\")\n",
    "                return\n",
    "\n",
    "            with open(schema_file, 'r') as f:\n",
    "                schema_sql = f.read()\n",
    "            \n",
    "            # Execute the full schema script\n",
    "            # We use the session-based connection for safety\n",
    "            db.execute_query(schema_sql)\n",
    "            print(\"Schema initialized successfully.\")\n",
    "        else:\n",
    "            print(\"All required tables are present. Ready to work.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d139bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fba27a",
   "metadata": {},
   "source": [
    "### **Populate Database Catalogs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d671e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_types = [\n",
    "    ('DocuHub Page',),\n",
    "    ('Publication',),\n",
    "    ('Dataset',),\n",
    "    ('GitHub Repository',),\n",
    "    ('Course',),\n",
    "    ('Presentation',)\n",
    "]\n",
    "\n",
    "with db_manager as db:\n",
    "    # 1. Insert Artifact Types one by one\n",
    "    print(\"Inserting Artifact Types...\")\n",
    "    db.execute_batch(\"INSERT INTO TBLArtifactTypes (TypeName) VALUES %s ON CONFLICT DO NOTHING;\", artifact_types)\n",
    "    \n",
    "    # 2. Get IDs for mapping (PostgreSQL returns lowercase keys in RealDictCursor)\n",
    "    res = db.execute_query(\"SELECT idArtifactType, TypeName FROM TBLArtifactTypes;\", fetch=True)\n",
    "    \n",
    "    if not res:\n",
    "        print(\"Error: TBLArtifactTypes is empty. Check your database connection or schema.\")\n",
    "    else:\n",
    "        # Build the map (Postgres column names are lowercase by default)\n",
    "        type_map = {r['typename']: r['idartifacttype'] for r in res}\n",
    "        print(f\"Mapping successful: {list(type_map.keys())}\")\n",
    "\n",
    "        # 3. Define Chunk Types\n",
    "        chunk_types = [\n",
    "            # For Publications (Papers)\n",
    "            (type_map['Publication'], 'Abstract'),\n",
    "            (type_map['Publication'], 'Background'),\n",
    "            (type_map['Publication'], 'Research Goal'),\n",
    "            (type_map['Publication'], 'Problem'),\n",
    "            (type_map['Publication'], 'Method'),\n",
    "            (type_map['Publication'], 'Data'),\n",
    "            (type_map['Publication'], 'Result'),\n",
    "            (type_map['Publication'], 'Discussion-Limitation'),\n",
    "            (type_map['Publication'], 'Conclusion'),\n",
    "\n",
    "            # [cite_start]For Datasets (HydroShare)\n",
    "            (type_map['Dataset'], 'Abstract'),\n",
    "            (type_map['Dataset'], 'Spatial Coverage'),\n",
    "            (type_map['Dataset'], 'Temporal Coverage'),\n",
    "            (type_map['Dataset'], 'Variable Metadata'),\n",
    "            (type_map['Dataset'], 'Data Services Info'),\n",
    "            (type_map['Dataset'], 'File Description'),\n",
    "            (type_map['Dataset'], 'Collection Contents'),\n",
    "            (type_map['Dataset'], 'Subject Keywords'),\n",
    "            (type_map['Dataset'], 'Related Resources Context'),\n",
    "\n",
    "            # [cite_start]For GitHub Repositories\n",
    "            (type_map['GitHub Repository'], 'Project Overview'),\n",
    "            (type_map['GitHub Repository'], 'Installation Setup'),\n",
    "            (type_map['GitHub Repository'], 'Usage Examples'),\n",
    "            (type_map['GitHub Repository'], 'Repository Structure'),\n",
    "            (type_map['GitHub Repository'], 'Contributing Guidelines'),\n",
    "            (type_map['GitHub Repository'], 'License Citation'),\n",
    "\n",
    "            # [cite_start]General/DocuHub\n",
    "            (type_map['DocuHub Page'], 'Section'),\n",
    "            (type_map['DocuHub Page'], 'Subsection'),\n",
    "            (type_map['DocuHub Page'], 'Subsubsection'),\n",
    "\n",
    "            # For Courses (HydroLearn)\n",
    "            (type_map['Course'], 'Problem Statement'),\n",
    "            (type_map['Course'], 'Module Overview'),\n",
    "            (type_map['Course'], 'Topic Covered'),\n",
    "            (type_map['Course'], 'Prerequisites'),\n",
    "            (type_map['Course'], 'Learning Objective'),\n",
    "            (type_map['Course'], 'Suggested Implementation'),\n",
    "            (type_map['Course'], 'Target Audience'),\n",
    "            (type_map['Course'], 'Author'),\n",
    "            (type_map['Course'], 'Tools Needed'),\n",
    "            (type_map['Course'], 'Expected Effort'),\n",
    "            (type_map['Course'], 'Citation'),\n",
    "\n",
    "            # For Presentations (HydroShare)\n",
    "            (type_map['Presentation'], 'Abstract'),\n",
    "            (type_map['Presentation'], 'Subject Keywords'),\n",
    "            (type_map['Presentation'], 'Collection Contents'),\n",
    "            (type_map['Presentation'], 'Related Resources Context')\n",
    "        ]\n",
    "        \n",
    "        # 4. Insert Chunk Types one by one\n",
    "        print(f\"Inserting {len(chunk_types)} Chunk Types...\")\n",
    "        db.execute_batch(\"INSERT INTO TBLChunkTypes (idArtifactType, TypeName) VALUES %s ON CONFLICT DO NOTHING;\", chunk_types)\n",
    "        \n",
    "        print(\"Catalogs populated successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIROH_AIBot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
