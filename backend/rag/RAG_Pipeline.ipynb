{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef4182e",
   "metadata": {},
   "source": [
    "# RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea60c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe904a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables\n",
    "load_dotenv()\n",
    "\n",
    "PG_HOST = os.getenv(\"POSTGRES_HOST\")\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\")\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\")\n",
    "PG_PASS = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\")\n",
    "\n",
    "BASE_URL = \"https://docs.ciroh.org\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fc560df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databes connection\n",
    "conn = psycopg2.connect(\n",
    "    host=PG_HOST,\n",
    "    database=PG_DB,\n",
    "    user=PG_USER,\n",
    "    password=PG_PASS\n",
    ")\n",
    "\n",
    "def execute_query(conn, query, params=None, fetch=False):\n",
    "    cur = conn.cursor()\n",
    "    \"\"\"Execute a SQL query with optional parameters.\"\"\"\n",
    "    try:\n",
    "        if params:\n",
    "            cur.execute(query, params)\n",
    "        else:\n",
    "            cur.execute(query)\n",
    "        if fetch:\n",
    "            result = cur.fetchall()\n",
    "            return result\n",
    "        else:\n",
    "            conn.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        conn.rollback()\n",
    "        return None\n",
    "    finally:\n",
    "        cur.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54333dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fbc380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_breadcrumb(conn, url_id):\n",
    "    \"\"\"\n",
    "    Generates the breadcrumb trail for a given idurl using a recursive query.\n",
    "\n",
    "    Args:\n",
    "        conn: The database connection object.\n",
    "        url_id: The idurl of the page for which to generate the trail.\n",
    "\n",
    "    Returns:\n",
    "        A string with the breadcrumb (e.g., \"Home > Products > NGIAB\"),\n",
    "        or None if an error occurs or the idurl is not found.\n",
    "    \"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    WITH RECURSIVE breadcrumb_path AS (\n",
    "        -- Anchor Member: Select the starting page\n",
    "        SELECT\n",
    "            idurl,\n",
    "            name,\n",
    "            idurlparent,\n",
    "            1 AS depth -- Initial depth level\n",
    "        FROM\n",
    "            tblurls\n",
    "        WHERE\n",
    "            idurl = %s\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        -- Recursive Member: Join the table to find the parent\n",
    "        SELECT\n",
    "            u.idurl,\n",
    "            u.name,\n",
    "            u.idurlparent,\n",
    "            bp.depth + 1 -- Increment depth at each level\n",
    "        FROM\n",
    "            tblurls u\n",
    "        JOIN\n",
    "            breadcrumb_path bp ON u.idurl = bp.idurlparent\n",
    "    )\n",
    "    -- Select the final result, aggregating the names into a single string\n",
    "    SELECT\n",
    "        string_agg(name, ' > ' ORDER BY depth DESC) AS breadcrumb\n",
    "    FROM\n",
    "        breadcrumb_path;\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        result = execute_query(conn, query, params=(url_id,), fetch=True)\n",
    "        \n",
    "        if result and result[0] and result[0][0]:\n",
    "            return result[0][0]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in get_breadcrumb for idurl {url_id}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fb74cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test questions\n",
    "'''\n",
    "questions = [\n",
    "    \"How can I get the meeting link to join the monthly CIROH office hours for AWS and cyberinfrastructure support?\",\n",
    "    \"What are the main differences between the Anvil and Derecho supercomputers?\",\n",
    "    \"What is the correct procedure for tagging an EC2 instance on AWS according to CIROH's convention?\",\n",
    "    \"I need to run a job on the Pantarhei cluster. What is the maximum duration and core count I can request for a single job without needing special permission?\",\n",
    "    \"I'm new to CIROH and want to start with hydrologic modeling. What is NextGen In A Box (NGIAB) and what are the main deployment options available?\"\n",
    "]\n",
    "'''\n",
    "questions = {\n",
    "    \"Getting Started & Navigation\": [\n",
    "        \"What is CIROH DocuHub and how can I use it?\",\n",
    "        \"How do I get started with CIROH services?\",\n",
    "        \"Where can I find the getting started guide?\",\n",
    "        \"How do I become a CIROH consortium member?\"\n",
    "    ],\n",
    "    \"Account & Access Requests\": [\n",
    "        \"How do I request access to CIROH infrastructure?\",\n",
    "        \"What are the requirements for using CIROH resources?\",\n",
    "        \"How do I request a new CIROH account?\",\n",
    "        \"How do I submit a request for new software installation?\",\n",
    "        \"How do I request access to JupyterHub?\",\n",
    "        \"How do I request GPU access for research?\",\n",
    "        \"How do I request AWS or Google Cloud access through CIROH?\",\n",
    "        \"How do I request access to the Pantarhei or Wukong HPC clusters?\",\n",
    "        \"How do I request access to the NWM BigQuery API?\"\n",
    "    ],\n",
    "    \"Documentation & Training\": [\n",
    "        \"Where can I find NextGen framework documentation?\",\n",
    "        \"Where can I find documentation for a specific CIROH tool?\",\n",
    "        \"Where can I access tutorials and training materials?\",\n",
    "        \"What educational resources are available for CIROH users?\"\n",
    "    ],\n",
    "    \"Contributing Content\": [\n",
    "        \"How do I contribute to CIROH DocuHub?\",\n",
    "        \"How do I add my project documentation?\",\n",
    "        \"Where do I submit tutorials or training materials?\",\n",
    "        \"How do I publish my research findings on DocuHub?\"\n",
    "    ],\n",
    "    \"Services & Infrastructure: JupyterHub\": [\n",
    "        \"How do I access CIROH JupyterHub?\",\n",
    "        \"What’s the difference between Production, Staging, and Workshop JupyterHub?\",\n",
    "        \"What software is pre-installed on JupyterHub?\",\n",
    "        \"How do I stop my JupyterHub server when I’m not using it?\",\n",
    "        \"How do I install custom software on JupyterHub?\"\n",
    "    ],\n",
    "    \"Services & Infrastructure: Cloud & HPC\": [\n",
    "        \"How do I request AWS cloud credits through CIROH?\",\n",
    "        \"What computing resources does CIROH offer?\",\n",
    "        \"How do I use the Pantarhei HPC cluster?\",\n",
    "        \"How do I access JetStream2?\",\n",
    "        \"How do I request compute resources for a workshop or training?\"\n",
    "    ],\n",
    "    \"Services & Infrastructure: Data Access\": [\n",
    "        \"How do I access the AORC dataset?\",\n",
    "        \"Where can I find forcing data for hydrological models?\",\n",
    "        \"How do I retrieve data for a specific region?\",\n",
    "        \"What data formats are supported by CIROH?\"\n",
    "    ],\n",
    "    \"NextGen Framework\": [\n",
    "        \"How do I get started with the NextGen framework?\",\n",
    "        \"What is NextGen In A Box (NGIAB)?\",\n",
    "        \"How do I run NextGen locally?\",\n",
    "        \"How do I configure NextGen for my basin?\",\n",
    "        \"How do I troubleshoot NextGen setup issues?\",\n",
    "        \"My NextGen model isn’t running—what should I check?\",\n",
    "        \"How do I resolve dependency conflicts in NextGen?\"\n",
    "    ],\n",
    "    \"Community & Collaboration\": [\n",
    "        \"How do I connect with other CIROH researchers?\",\n",
    "        \"How do I join CIROH office hours?\",\n",
    "        \"How do I provide feedback on CIROH services?\"\n",
    "    ],\n",
    "    \"Technical Support\": [\n",
    "        \"I can’t access my JupyterHub environment—what should I do?\",\n",
    "        \"My data processing job failed—how can I troubleshoot?\",\n",
    "        \"How do I optimize my computational resources?\",\n",
    "        \"I need help with processing large datasets—where do I start?\",\n",
    "        \"How do I report a bug or issue to CIROH IT support?\"\n",
    "    ],\n",
    "    \"Data & Workflow Best Practices\": [\n",
    "        \"What are the best practices for managing CIROH datasets?\",\n",
    "        \"How do I ensure reproducibility in my CIROH research?\",\n",
    "        \"What tools are available for data visualization in CIROH?\",\n",
    "        \"How do I convert between different hydrological data formats?\"\n",
    "    ],\n",
    "    \"Policies & Administration\": [\n",
    "        \"What are CIROH’s usage policies?\",\n",
    "        \"How much compute time am I allocated?\",\n",
    "        \"What are the CIROH data sharing policies?\",\n",
    "        \"Are there restrictions on using CIROH resources for commercial work?\"\n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b29167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, dimensions, model=EMBEDDING_MODEL):\n",
    "    \"\"\"Call OpenAI to get an embedding for the given text.\"\"\"\n",
    "    try:\n",
    "        response = openai.embeddings.create(\n",
    "            input=text,\n",
    "            model=model,\n",
    "            dimensions=dimensions\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error generating embedding: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac1a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_embedding(question_embedding):\n",
    "    \"\"\"Queries the database to find the most relevant summaries.\"\"\"\n",
    "    # The query finds the top 3 most similar summaries using cosine similarity (<=>)\n",
    "    # The trailing comma in `params=(question_embedding,)` is crucial to ensure it's a tuple.\n",
    "    responses = execute_query(conn, \"\"\"\n",
    "        SELECT idurl, summary_data ->> 'summary_text' as summary\n",
    "        FROM tblurls\n",
    "        WHERE summary_data IS NOT NULL\n",
    "        ORDER BY embedding <=> %s::vector\n",
    "        LIMIT 3\n",
    "    \"\"\", params=(question_embedding,), fetch=True)\n",
    "    \n",
    "    # Return the database rows\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99a1b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rag_prompt(question, context_summaries):\n",
    "    \"\"\"Builds the prompt for the LLM to answer the question based on context.\"\"\"\n",
    "    \n",
    "    # Joins the retrieved summaries into a single block of text\n",
    "    context_str = \"\\n\\n---\\n\\n\".join(context_summaries)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are an expert AI assistant for the CIROH DocuHub. Your task is to answer the user's question based *only* on the provided context.\n",
    "\n",
    "If the context does not contain the answer, state that you cannot answer the question with the information given. Do not use any external knowledge.\n",
    "\n",
    "**CONTEXT:**\n",
    "---\n",
    "{context_str}\n",
    "---\n",
    "\n",
    "**QUESTION:**\n",
    "{question}\n",
    "\n",
    "**ANSWER:**\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "096519d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final answer from the LLM\n",
    "def get_rag_answer(prompt):\n",
    "    \"\"\"Calls the LLM to generate the final answer.\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-5\", # Or your preferred model\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            reasoning_effort=\"minimal\",\n",
    "            verbosity=\"low\"\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error generating RAG answer: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c4795d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_chunks(question_embedding, relevant_url_ids):\n",
    "    \"\"\"\n",
    "    Queries the TBLContent table to find the most relevant chunks\n",
    "    only within the pages identified in the first-level search.\n",
    "    \"\"\"\n",
    "    # The query searches for the top 5 most similar chunks, but only\n",
    "    # within the list of provided idurls.\n",
    "    responses = execute_query(conn, \"\"\"\n",
    "        SELECT idurl, \"order\", Content\n",
    "        FROM TBLContent\n",
    "        WHERE idurl = ANY(%s)\n",
    "        ORDER BY embedding <=> %s::vector\n",
    "        LIMIT 5;\n",
    "    \"\"\", params=(relevant_url_ids, question_embedding), fetch=True)\n",
    "    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8534e5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "TOPIC: Getting Started & Navigation\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: What is CIROH DocuHub and how can I use it?\n",
      "\n",
      "✅ Final Answer:\n",
      "CIROH DocuHub is the centralized entry point for CIROH documentation, services, and community resources that support hydrologic research and operations. It links you to computing environments (CIROH-2i2c JupyterHub on Google Cloud, CIROH AWS, Google Cloud, Pantarhei HPC), product documentation (NextGen, Snow model, Tethys, NextGen In A Box), policies, training, blogs, and collaboration tools (CIROH Portal). It also hosts monthly NextGen-focused office hours, showcases community contributions, and lists sponsors, members, and partners.\n",
      "\n",
      "How to use it:\n",
      "- Explore: Find docs, training, product pages, and links to computing resources and the CIROH Research Portal.\n",
      "- Contribute: \n",
      "  - Click “Edit page” on docs.ciroh.org to propose documentation changes via GitHub pull requests.\n",
      "  - Submit blog posts (highlighting projects using CIROH cyberinfrastructure) via the blog issue template on GitHub for review.\n",
      "  - Request new product pages for public GitHub projects via the product issue template.\n",
      "- Get support: Use Slack, email, or the site’s contact page. Developer resources cover repository workflows, site tech, and blog authoring. The site is built with Docusaurus.\n",
      "\n",
      "🔗 Sources:\n",
      "- DocuHub\n",
      "- DocuHub > Contributing to CIROH DocuHub\n",
      "- Products > CIROH Research Portal\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: How do I get started with CIROH services?\n",
      "\n",
      "✅ Final Answer:\n",
      "You can get started by requesting access and joining support sessions:\n",
      "\n",
      "- Request access: Use the Infrastructure Access page and linked GitHub issue forms to obtain a CIROH AWS subaccount (and other resources as needed). CIROH will create the subaccount and PI identity; your project team manages the environment and user access.\n",
      "- Use the managed JupyterHub and preconfigured environments provided by the CIROH CyberInfrastructure (AWS, Google Cloud, Pantarhei HPC) for scalable compute/storage and pre-installed hydrologic software.\n",
      "- Join Cyberinfrastructure and Community NextGen Office Hours: Email ciroh-it-admin@ua.edu to receive the Microsoft Teams link and calendar invite for monthly sessions on accessing and using CIROH resources.\n",
      "- For ongoing help, see CIROH CyberInfrastructure documentation and reach out via the listed support channels (email and Slack).\n",
      "\n",
      "🔗 Sources:\n",
      "- Services\n",
      "- Services > Public Cloud > CIROH AWS Account\n",
      "- Products > NextGen In A Box > Cyberinfrastructure and Community NextGen Office Hours\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: Where can I find the getting started guide?\n",
      "\n",
      "✅ Final Answer:\n",
      "See the “Intro to NGIAB” page—it directs you to the NGIAB 101 learning module and local installation guidance as the getting started resources.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Intro to NGIAB > Installing NGIAB Locally\n",
      "- Products > NGIAB 101 Learning Module > Installation and Setup\n",
      "- Products > NextGen In A Box > Intro to NGIAB\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: How do I become a CIROH consortium member?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t answer that with the information given. The provided context covers CIROH services and access to infrastructure but does not explain how to become a consortium member.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Pantarhei > Obtaining an Account\n",
      "- Services\n",
      "- Services > Public Cloud > CIROH AWS Account\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Account & Access Requests\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: How do I request access to CIROH infrastructure?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Project leads request resources via the CIROH GitHub issue templates (project-level On-Premises Infrastructure Request for on-prem HPC; similar templates for cloud/JupyterHub needs).\n",
      "- Individuals then request access:\n",
      "  - For on-prem HPC (Pantarhei/Wukong): submit the Microsoft Forms On-Premises Access Request after PI approval. UA users submit only this form; non-UA users must first obtain VPN access, then submit the form.\n",
      "  - For JupyterHub CPU/GPU and custom images: follow the JupyterHub access process linked from Infrastructure Access.\n",
      "- If you can’t access the forms, email ciroh-it-admin@ua.edu for assistance.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Pantarhei > Obtaining an Account\n",
      "- Services > Infrastructure Access\n",
      "- Services\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: What are the requirements for using CIROH resources?\n",
      "\n",
      "✅ Final Answer:\n",
      "I cannot answer with the information given. The provided context describes CIROH policies and services but does not state specific requirements for using CIROH resources.\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies\n",
      "- Policies > Data and Code Sharing > Policy and Guidance\n",
      "- Services\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: How do I request a new CIROH account?\n",
      "\n",
      "✅ Final Answer:\n",
      "Use the CIROH Infrastructure Access workflow:\n",
      "- For on-prem (Pantarhei): PI initiates a project-level On-Premises Infrastructure Request via the GitHub issue template, then each user submits the Microsoft Forms On-Premise Access Request. UA users submit only the On-Premises Access Request. External users must obtain VPN access before submitting the On-Premises Access Request.\n",
      "- For cloud (AWS or Google Cloud): Submit the request via the Infrastructure Access page using the referenced GitHub issue forms to have CIROH create a project subaccount and PI identity.\n",
      "\n",
      "If you can’t access the forms, email ciroh-it-admin@ua.edu.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Pantarhei > Obtaining an Account\n",
      "- Services > Public Cloud > CIROH AWS Account\n",
      "- Services > Public Cloud > CIROH Google Account\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: How do I submit a request for new software installation?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Export your conda environment to an environment.yml.\n",
      "- Fill out the JupyterHub (2i2c) Software Install Form and select the CIROH 2i2c installation.\n",
      "- Email the environment.yml to CIROH-IT support.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial > Request custom images\n",
      "- Services > On-Premises > Pantarhei > Obtaining an Account\n",
      "- Services > CIROH Subdomain Request Form\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 5: How do I request access to JupyterHub?\n",
      "\n",
      "✅ Final Answer:\n",
      "- CIROH JupyterHub: Request access through CIROH’s Infrastructure Access process (then you can use the production/staging/workshop hubs). For help, contact CIROH Cloud via email or Slack.\n",
      "- CUAHSI JupyterHub: Join the CUAHSI JupyterHub Group via your HydroShare account. You can then launch from HydroShare (Apps library or “Open with”) or go to jupyterhub.cuahsi.org. For support, email help@cuahsi.org.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH JupyterHub\n",
      "- Services > Public Cloud > CUAHSI JupyterHub\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial > Request custom images\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 6: How do I request GPU access for research?\n",
      "\n",
      "✅ Final Answer:\n",
      "- For on-prem HPC (Pantarhei or Wukong): Have your PI submit a project-level On‑Premises Infrastructure Request via the GitHub issue template specifying GPU needs. Then each user submits the On‑Premise Access Request form (external users obtain VPN access first via the same workflow). CIROH IT Computing (UA) provisions per-user accounts.\n",
      "\n",
      "- For JupyterHub: Use the Infrastructure Access process to request individual CPU/GPU access (including custom images) after PI/project approval.\n",
      "\n",
      "If you can’t access the forms, email ciroh-it-admin@ua.edu.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Wukong > Obtaining an Account\n",
      "- Services > On-Premises > Pantarhei > Obtaining an Account\n",
      "- Services > Infrastructure Access\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 7: How do I request AWS or Google Cloud access through CIROH?\n",
      "\n",
      "✅ Final Answer:\n",
      "Request access via the CIROH Infrastructure Access workflow. Submit the referenced GitHub issue form to request a project subaccount; CIROH will create the AWS/Google Cloud subaccount and PI identity. For help, contact ciroh-it-admin@ua.edu or the CIROH IT Slack channel.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH Google Account\n",
      "- Services > Public Cloud > CIROH AWS Account\n",
      "- Blog > CIROH Research CyberInfrastructure Update\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 8: How do I request access to the Pantarhei or Wukong HPC clusters?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Pantarhei:\n",
      "  - Step 1 (project): Have the PI open an On‑Premises Infrastructure Request via the GitHub issue template.\n",
      "  - Step 2 (user): Each user submits the Microsoft Forms On‑Premise Access Request.\n",
      "  - UA users: submit only the On‑Premises Access Request.\n",
      "  - External users: obtain VPN access first, then submit the On‑Premises Access Request.\n",
      "  - If you can’t access forms, email ciroh-it-admin@ua.edu.\n",
      "\n",
      "- Wukong:\n",
      "  - PI opens a GitHub On‑premises Infrastructure Request issue with project details and a roster of users (GitHub usernames and emails).\n",
      "  - Each user submits the CIROH On‑Premise Access Form separately.\n",
      "  - Non‑UA users without MyBama/VPN/CWID must request VPN access via the same form workflow before account provisioning.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Wukong > Obtaining an Account\n",
      "- Services > On-Premises > Pantarhei > Obtaining an Account\n",
      "- Services > On-Premises > Pantarhei > Accessing the System\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 9: How do I request access to the NWM BigQuery API?\n",
      "\n",
      "✅ Final Answer:\n",
      "Submit the NWM BigQuery API Access Form. After approval, you’ll receive an API key and can use the API at https://nwm-api.ciroh.org.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > Data Management and Access Tools > NWM BigQuery API\n",
      "- Blog > Accessing National Water Model (NWM) Data via Google Cloud BigQuery API\n",
      "- Services > Public Cloud > CIROH Google Account\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Documentation & Training\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: Where can I find NextGen framework documentation?\n",
      "\n",
      "✅ Final Answer:\n",
      "- NextGen Technical Guidance page (with a link to the full guidance PDF) as the authoritative integration and design reference.\n",
      "- NextGen framework presentation page (includes a link to a CIROH webinar by Fred L. Ogden for detailed background).\n",
      "- NextGen In A Box (NGIAB) page (links to installation guidance and deeper framework background).\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies > NextGen Framework\n",
      "- Products > National Water Model > NextGen Framework\n",
      "- Products > NextGen In A Box > Distributions > NGIAB-CloudInfra > Getting Started\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: Where can I find documentation for a specific CIROH tool?\n",
      "\n",
      "✅ Final Answer:\n",
      "On the CIROH DocuHub. It’s the centralized entry point linking to product documentation (e.g., NextGen, Snow model, Tethys, NextGen In A Box) and other CIROH tools.\n",
      "\n",
      "🔗 Sources:\n",
      "- DocuHub\n",
      "- Policies\n",
      "- Products > Snow Sensing and Modeling Tools > Intro to Snow Observations Modeling Analysis\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: Where can I access tutorials and training materials?\n",
      "\n",
      "✅ Final Answer:\n",
      "Use the NGIAB 101 module and the Learner Profiles page. NGIAB 101 provides the structured training (episodes from setup to advanced topics), links to source code on GitHub, core docs on CIROH Docs, quick-start paths, Key Points, and a Glossary. The Learner Profiles page routes you to the right path (general, HPC, or DevCon 2025 Jetstream instructions with troubleshooting).\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NGIAB 101 Learning Module > Learner Profiles\n",
      "- Products > NGIAB 101 Learning Module\n",
      "- Products > NGIAB 101 Learning Module > Instructor - Summary and Schedule > Instructor Notes\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: What educational resources are available for CIROH users?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Educational courses via the CIROH Research Portal\n",
      "- Training resources linked from CIROH DocuHub (product documentation, tutorials)\n",
      "- Monthly NextGen-focused office hours\n",
      "- Blogs and community-contributed tutorials, datasets, and presentations\n",
      "- YouTube overview of CIROH Services by the Research CyberInfrastructure and DevOps Team\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > CIROH Research Portal\n",
      "- DocuHub\n",
      "- Services\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Contributing Content\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: How do I contribute to CIROH DocuHub?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Minor edits: Click “Edit page” on docs.ciroh.org, make changes, and submit a pull request to the GitHub repo for admin review.\n",
      "- Major edits: Fork CIROH-UA/ciroh-ua_website, commit changes, open a pull request; GitHub Actions will build and publish. You can develop locally with Node.js (npm install, npm run start/build).\n",
      "- Blog posts: Must showcase projects using CIROH cyberinfrastructure. Submit via the blog post GitHub issue template for CIROH tech team review.\n",
      "- Product pages: Ensure your project is public on GitHub with a clear README. Request a page via the product issue template.\n",
      "- Help: See developer resources for workflows/tech and blog authoring guides. Support via Slack, ciroh-it-admin@ua.edu, or the site’s contact page.\n",
      "\n",
      "🔗 Sources:\n",
      "- DocuHub > Contributing to CIROH DocuHub\n",
      "- DocuHub > Contributing to CIROH DocuHub > Working with the DocuHub repository\n",
      "- DocuHub\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: How do I add my project documentation?\n",
      "\n",
      "✅ Final Answer:\n",
      "- For simple fixes or small changes: click “Edit page” on docs.ciroh.org, make your edits, and submit a pull request to the GitHub repo for review.\n",
      "- For larger additions or new docs: fork CIROH-UA/ciroh-ua_website, add your Markdown content, commit, and open a pull request. GitHub Actions will build and publish after review.\n",
      "- To request a product page for your project: ensure it has a public GitHub repo with a clear README, then submit the dedicated Product Page issue template in the DocuHub repo.\n",
      "- You can develop locally with Node.js: npm install, npm run start (dev) or npm run build (prod).\n",
      "- Support: Slack, ciroh-it-admin@ua.edu, or the site’s contact page.\n",
      "\n",
      "🔗 Sources:\n",
      "- DocuHub > Contributing to CIROH DocuHub\n",
      "- DocuHub > Contributing to CIROH DocuHub > Working with the DocuHub repository\n",
      "- DocuHub > Contributing to CIROH DocuHub > DocuHub technologies\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: Where do I submit tutorials or training materials?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t determine that from the provided information.\n",
      "\n",
      "🔗 Sources:\n",
      "- DocuHub > Contributing to CIROH DocuHub > Working with the DocuHub repository\n",
      "- DocuHub > Contributing to CIROH DocuHub\n",
      "- Products > NGIAB 101 Learning Module > Advanced Topics\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: How do I publish my research findings on DocuHub?\n",
      "\n",
      "✅ Final Answer:\n",
      "You can contribute your research via DocuHub’s contribution pathways:\n",
      "\n",
      "- Documentation/tutorials: Use the “Edit page” link on docs.ciroh.org for minor edits (submit a pull request). For major new pages/tutorials, fork CIROH-UA/ciroh-ua_website, commit your content, and open a pull request; GitHub Actions will build and publish after review.\n",
      "- Blog post: Submit via the blog issue template in the GitHub repository. Posts should highlight projects using CIROH cyberinfrastructure and will be reviewed by CIROH’s tech team.\n",
      "- Product page (if applicable): Ensure your project has a public GitHub repo with a clear README, then request a page via the product issue template.\n",
      "\n",
      "For help, contact ciroh-it-admin@ua.edu or use Slack/contact page.\n",
      "\n",
      "🔗 Sources:\n",
      "- DocuHub > Contributing to CIROH DocuHub > Working with the DocuHub repository\n",
      "- DocuHub > Contributing to CIROH DocuHub\n",
      "- DocuHub\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Services & Infrastructure: JupyterHub\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: How do I access CIROH JupyterHub?\n",
      "\n",
      "✅ Final Answer:\n",
      "Access is provided through CIROH’s Infrastructure Access process. Once you have access, you can use the production, staging, or workshop hubs as appropriate. For guidance, see the CIROH JupyterHub documentation and the linked video tutorial; support is available via CIROH Cloud email and Slack.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH JupyterHub\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial\n",
      "- Services > Public Cloud > HydroShare and CIROH JupyterHub Integration\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: What’s the difference between Production, Staging, and Workshop JupyterHub?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Production: Main CIROH JupyterHub for everyday research use; persistent user homes, multiple server sizes, consortium-funded service.\n",
      "- Staging: Separate hub used for testing/validation before changes go to Production.\n",
      "- Workshop: Time-limited hub provisioned for events/workshops; available only for the event duration.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH JupyterHub\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial > JupyterHub User Directory\n",
      "- Services > Public Cloud > CUAHSI JupyterHub\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: What software is pre-installed on JupyterHub?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t determine the specific pre-installed software from the provided information. The context mentions a link to the deployed software Dockerfile and CIROH hub image repository where the environment is defined, but the actual package list isn’t included here.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH JupyterHub\n",
      "- Services > Public Cloud > CUAHSI JupyterHub\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: How do I stop my JupyterHub server when I’m not using it?\n",
      "\n",
      "✅ Final Answer:\n",
      "Use JupyterHub’s “Stop My Server” when you’re done. From your JupyterLab session, go to the JupyterHub control (top-right hub menu or your user menu) and choose Stop My Server. This frees resources and is required when idle.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial > Prevent Server Timeout\n",
      "- Services > Public Cloud > CIROH JupyterHub\n",
      "- Services > Public Cloud > CUAHSI JupyterHub\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 5: How do I install custom software on JupyterHub?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Export your conda environment to an environment.yml.\n",
      "- Submit the JupyterHub (2i2c) Software Install Form, selecting the CIROH 2i2c installation.\n",
      "- Email the environment.yml to CIROH-IT support.\n",
      "\n",
      "This enables a reproducible, environment-specific software stack on CIROH’s JupyterHub.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial > Request custom images\n",
      "- Services > Public Cloud > CIROH JupyterHub\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial > Push and Pull to GitHub\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Services & Infrastructure: Cloud & HPC\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: How do I request AWS cloud credits through CIROH?\n",
      "\n",
      "✅ Final Answer:\n",
      "Use the CIROH Infrastructure Access workflow and the referenced GitHub issue forms to request access and funding. CIROH provides a default $500/month budget across AWS and Google Cloud; you can request additional funds by submitting the designated GitHub issue template linked from the Infrastructure Access page. For help, contact the CIROH IT admin email or the Slack support channel.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH AWS Account\n",
      "- Services > Public Cloud > CIROH Google Account\n",
      "- Services > Public Cloud > CIROH AWS Account > CIROH AWS Office Hours\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: What computing resources does CIROH offer?\n",
      "\n",
      "✅ Final Answer:\n",
      "CIROH offers a multi-cloud and on‑premise CyberInfrastructure, including:\n",
      "- Managed JupyterHub with preconfigured environments and hydrologic software\n",
      "- Compute and storage on AWS, Google Cloud, and the Pantarhei HPC cluster\n",
      "- Google BigQuery API access for National Water Model data (via ciroh-it-admin@ua.edu)\n",
      "- Optional GPU allocations on the 2i2c JupyterHub (by request)\n",
      "- Guidance and support for NSF ACCESS allocations to supplement resources\n",
      "\n",
      "🔗 Sources:\n",
      "- Services\n",
      "- Blog > CIROH Research CyberInfrastructure Update\n",
      "- Services > External Resources\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: How do I use the Pantarhei HPC cluster?\n",
      "\n",
      "✅ Final Answer:\n",
      "Pantarhei is CIROH’s on‑premises HPC cluster at the University of Alabama for hydrologic research. To use it:\n",
      "\n",
      "- Ensure compliance with UA policies (acceptable use, information classification/protection) and obtain a Pantarhei account.\n",
      "- Access the system: connect to the UA network via VPN, then SSH to pantarhei.ua.edu using your Pantarhei username/password. Manage SSH public keys as needed. UA OIT resources provide VPN setup.\n",
      "- Run workloads via Slurm: submit compute work as Slurm jobs (don’t run intensive tasks on login nodes). Choose appropriate queues for CPU, GPU, or FPGA. Shared-node jobs are supported. Jobs can run up to 7 days and use up to six full nodes; standard max job size is 240 cores. Larger requests require a support consultation.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Pantarhei > Running Jobs > Accessing the Compute Nodes\n",
      "- Services > On-Premises > Pantarhei > Accessing the System\n",
      "- Services > On-Premises > Pantarhei\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: How do I access JetStream2?\n",
      "\n",
      "✅ Final Answer:\n",
      "Request an allocation through CIROH’s Infrastructure Access process. The page directs CIROH researchers to request Jetstream2 via NSF ACCESS through CIROH’s Infrastructure Access, with technical details on the official Jetstream2 documentation site.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > External Resources > NSF Access > JetStream2\n",
      "- Services > Infrastructure Access\n",
      "- Services > On-Premises > Pantarhei > Accessing the System\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 5: How do I request compute resources for a workshop or training?\n",
      "\n",
      "✅ Final Answer:\n",
      "Use the Infrastructure Access process: the PI or workshop lead submits a project resource request via the provided GitHub templates. This covers allocating platforms (e.g., CIROH-2i2c JupyterHub, AWS/Google Cloud, JetStream2, on-prem HPC) and any needed storage or services. For JupyterHub software needs, export your conda env to environment.yml, submit the JupyterHub (2i2c) Software Install Form (select CIROH 2i2c), and email the environment.yml to CIROH-IT. For conference/workshop IT support, follow the Infrastructure Access page’s support request process and contacts.\n",
      "\n",
      "🔗 Sources:\n",
      "- Blog > DevCon 2025: A DevOps and Cyberinfrastructure Success Story\n",
      "- Services > Infrastructure Access\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial > Request custom images\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Services & Infrastructure: Data Access\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: How do I access the AORC dataset?\n",
      "\n",
      "✅ Final Answer:\n",
      "You can access AORC via:\n",
      "- HydroShare/CIROH 2i2c JupyterHub: Use the “AORC Data in Your Hands” Jupyter notebooks (requires a HydroShare account and CIROH-2i2c JupyterHub authorization via GitHub) to retrieve and aggregate AORC precipitation/meteorological data from AWS.\n",
      "- NOAA Open Data Dissemination (NODD) cloud: Access AORC as part of NWM forcings referenced on the Data Access page; AWS hosts operational and retrospective datasets, with examples and Kerchunk catalogs provided for cloud-based use.\n",
      "\n",
      "Development versions of the notebooks are on the CUAHSI GitHub.\n",
      "\n",
      "🔗 Sources:\n",
      "- Blog > AORC Data in Your Hands: User-Friendly Jupyter Notebooks for Data Retrieval and Analysis via CIROH JupyterHub Notebooks\n",
      "- Products > Data Management and Access Tools > Data Access\n",
      "- Services > External Resources > NSF Access\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: Where can I find forcing data for hydrological models?\n",
      "\n",
      "✅ Final Answer:\n",
      "- National Water Model (NWM) forcings via NOAA/NCEP NOMADS (HTTP/FTP): operational, post-processed, para_post-processed directories\n",
      "- NOAA Open Data Dissemination (NODD) in the cloud: AWS, Google Cloud, Azure/Planetary Computer (includes operational and retrospective archives)\n",
      "- CIROH-hosted Kerchunk catalogs for NWM datasets\n",
      "- AORC v1.0 (and forthcoming v1.1) for long-term hydrologic modeling\n",
      "- Research DataStream: daily NextGen forcings on AWS S3 (browse at datastream.ciroh.org)\n",
      "- NextGen Framework Forcings GitHub: processor to convert NWM-based datasets into ngen forcing files\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > Research Datastream\n",
      "- Blog > NextGen Framework Forcings\n",
      "- Products > Data Management and Access Tools > Data Access\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: How do I retrieve data for a specific region?\n",
      "\n",
      "✅ Final Answer:\n",
      "Use the “AORC Data in Your Hands” Jupyter notebooks on CIROH’s 2i2c JupyterHub. They support spatial subsetting for both point and polygon (shapefile) workflows in latitude–longitude and NWM-projected formats. You’ll need a HydroShare account to access the notebooks and GitHub authorization for the CIROH-2i2c JupyterHub.\n",
      "\n",
      "🔗 Sources:\n",
      "- Blog > AORC Data in Your Hands: User-Friendly Jupyter Notebooks for Data Retrieval and Analysis via CIROH JupyterHub Notebooks\n",
      "- Products > Data Management and Access Tools > Data Access\n",
      "- Blog > Accessing National Water Model (NWM) Data via Google Cloud BigQuery API\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: What data formats are supported by CIROH?\n",
      "\n",
      "✅ Final Answer:\n",
      "I cannot answer with the information given. The provided context does not list CIROH-supported data formats.\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies\n",
      "- Policies > Data and Code Sharing > Policy and Guidance\n",
      "- Products > CIROH Research Portal\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: NextGen Framework\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: How do I get started with the NextGen framework?\n",
      "\n",
      "✅ Final Answer:\n",
      "Start with the NGIAB 101 training module linked from the Intro to NGIAB page. Use the Intro to NGIAB hub to review the overview of capabilities, glossary, and run configuration directory structure, then follow the local installation guidance to set up NGIAB. For framework concepts and module execution via BMI and run realization files, see the NextGen framework presentation page and the linked CIROH webinar by Fred L. Ogden.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Distributions > NGIAB-CloudInfra > Getting Started\n",
      "- Products > National Water Model > NextGen Framework\n",
      "- Products > NextGen In A Box > Intro to NGIAB\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: What is NextGen In A Box (NGIAB)?\n",
      "\n",
      "✅ Final Answer:\n",
      "NextGen In A Box (NGIAB) is an open-source, containerized distribution of the Next Generation Water Resources Modeling Framework (NextGen) that packages BMI-compliant models, hydrofabric data, and the ngen engine with standardized dependencies. It streamlines installation and execution across local, cloud, and HPC environments, enabling rapid, reproducible hydrologic modeling (including NWM configurations) with tools for data preprocessing, model execution, evaluation, visualization, and calibration.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NGIAB 101 Learning Module > Introduction\n",
      "- Products > NextGen In A Box > Intro to NGIAB > NWM, NextGen, and NGIAB\n",
      "- Products > NGIAB 101 Learning Module > Key Points\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: How do I run NextGen locally?\n",
      "\n",
      "✅ Final Answer:\n",
      "To run NextGen locally with NGIAB:\n",
      "\n",
      "1) Install prerequisites:\n",
      "- Install Docker Desktop (Windows via WSL, macOS, or Linux).\n",
      "- Verify Docker works: docker ps -a.\n",
      "- On Windows, avoid WSL distributions linked to Docker.\n",
      "\n",
      "2) Prepare a workspace and data:\n",
      "- Create a project directory.\n",
      "- Download and extract the Sipsey Fork sample input data.\n",
      "\n",
      "3) Get NGIAB-CloudInfra:\n",
      "- Clone the NGIAB-CloudInfra repository.\n",
      "\n",
      "4) Use the interactive guide:\n",
      "- Run guide.sh to validate your local setup and configure/execute a run. It can also launch the Tethys visualizer and other services.\n",
      "\n",
      "Notes:\n",
      "- For custom inputs, use NGIAB-datapreprocessor or the Data Preprocess tool to subset hydrofabric, generate forcings, and create realization files in the standard ngen-run directory, then execute via guide.sh.\n",
      "- See the NGIAB 101 training module for troubleshooting (e.g., LF vs CRLF line endings).\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Intro to NGIAB > Installing NGIAB Locally\n",
      "- Products > NGIAB 101 Learning Module > DevCon 2025 Jetstream VM Instructions\n",
      "- Products > NGIAB 101 Learning Module > Key Points\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: How do I configure NextGen for my basin?\n",
      "\n",
      "✅ Final Answer:\n",
      "Use NGIAB’s provided workflow:\n",
      "- Install NGIAB (Docker locally; Singularity on HPC) and run guide.sh.\n",
      "- Prepare inputs with the Data Preprocess tool: subset the hydrofabric for your basin, generate forcings, and create a realization file. Outputs are organized in a standard ngen-run directory.\n",
      "- Configure your basin-specific run by editing the generated realization file to set modules, parameters, and execution order for your control volumes.\n",
      "- Execute the NextGen run from the ngen-run directory (either directly after preprocessing or separately).\n",
      "- Optionally calibrate with ngiab-cal (YAML-driven), evaluate skill with TEEHR against USGS/NWM, and visualize results with the Tethys-based Data Visualizer (guide.sh or ViewOnTethys.sh).\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Distributions > NGIAB-CloudInfra > Getting Started\n",
      "- Products > National Water Model > NextGen Framework\n",
      "- Products > NGIAB 101 Learning Module > Key Points\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 5: How do I troubleshoot NextGen setup issues?\n",
      "\n",
      "✅ Final Answer:\n",
      "Use the NGIAB 101 training module for onboarding and troubleshooting (including Git line endings LF vs CRLF). For setup validation, run the interactive guide (guide.sh) in NGIAB-CloudInfra. If issues persist, open a GitHub issue, attend CIROH monthly office hours, or reach out via email/CIROH Slack.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Distributions > NGIAB-CloudInfra > Getting Started\n",
      "- Products > NextGen In A Box > Distributions > NGIAB-CloudInfra > Contact Us\n",
      "- Products > NextGen In A Box > Intro to NGIAB > Installing NGIAB Locally\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 6: My NextGen model isn’t running—what should I check?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Verify your run directory follows the required NextGen Run Directories structure: ngen-run root with config, forcings, outputs, and metadata (optional lakeout, restart).\n",
      "- Confirm the config folder contains a valid realization file and BMI configs; if using per-catchment configs, ensure they are in config/cat-config and correctly referenced (e.g., PET, CFE, NOAH-OWP-M).\n",
      "- Ensure a single hydrofabric geopackage is present in config and matches the catchments used by your configs and forcings.\n",
      "- Check forcings exist for all modeled catchments and cover the simulation time window.\n",
      "- If using NGIAB, confirm the Data Preprocess tool completed successfully and auto-built the run directory accordingly.\n",
      "- Review the ordered module sequence in your realization file to ensure required BMI components are defined and compatible.\n",
      "- If containerized (NGIAB), make sure the Docker image/version and dependencies are correct and the runtime is consistent with your configs.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > National Water Model > NextGen Framework\n",
      "- Products > NextGen In A Box > Distributions > NGIAB-CloudInfra > Getting Started\n",
      "- Products > NextGen In A Box > Intro to NGIAB > Run Configuration Directory Structure\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 7: How do I resolve dependency conflicts in NextGen?\n",
      "\n",
      "✅ Final Answer:\n",
      "I cannot answer with the information given. The provided context does not mention dependency management or conflict resolution procedures for NextGen.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > National Water Model > NextGen Framework\n",
      "- Policies > NextGen Framework\n",
      "- Blog > NextGen Framework Forcings\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Community & Collaboration\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: How do I connect with other CIROH researchers?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t answer that with the information given. The context mentions CIROH Cyberinfrastructure and Community NextGen Office Hours (email ciroh-it-admin@ua.edu for the Teams link) and the CIROH Research Portal (portal.ciroh.org), which may help you find resources and apps, but it doesn’t specify networking channels for connecting with researchers.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Cyberinfrastructure and Community NextGen Office Hours\n",
      "- Products > CIROH Research Portal\n",
      "- Blog > CIROH Science Meeting 2024\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: How do I join CIROH office hours?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Cyberinfrastructure and Community NextGen Office Hours: Email ciroh-it-admin@ua.edu to receive the Microsoft Teams meeting link and calendar invite.\n",
      "- AWS Office Hours: Use the contact email provided on the AWS Office Hours page to subscribe and receive session details.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Cyberinfrastructure and Community NextGen Office Hours\n",
      "- Services > Public Cloud > CIROH AWS Account > CIROH AWS Office Hours\n",
      "- Blog > CIROH Research CyberInfrastructure Update\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: How do I provide feedback on CIROH services?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t determine the feedback process from the provided information. The context mentions support via Slack, email, and the site’s contact page for DocuHub contributions, but it doesn’t specify how to provide feedback on CIROH services.\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies\n",
      "- DocuHub > Contributing to CIROH DocuHub\n",
      "- Services\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Technical Support\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: I can’t access my JupyterHub environment—what should I do?\n",
      "\n",
      "✅ Final Answer:\n",
      "- For CIROH JupyterHub:\n",
      "  - Ensure you have CIROH Infrastructure Access and are using the correct hub (production/staging/workshop). The workshop hub may be time-limited.\n",
      "  - Try stopping and restarting your server; select an appropriate server size.\n",
      "  - If issues persist, contact CIROH Cloud support via email or Slack; you can also email ciroh-it-admin@ua.edu.\n",
      "\n",
      "- For CUAHSI JupyterHub:\n",
      "  - Make sure you’ve joined the CUAHSI JupyterHub Group in HydroShare.\n",
      "  - Launch from HydroShare (Apps library or “Open with”) or directly at jupyterhub.cuahsi.org and select a profile.\n",
      "  - If you still can’t access, email help@cuahsi.org.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CUAHSI JupyterHub\n",
      "- Services > Public Cloud > CIROH JupyterHub\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: My data processing job failed—how can I troubleshoot?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t answer with the information given. The context only describes how to submit and run jobs on Pantarhei (via Slurm queues) and how to execute NGIAB model runs, but it doesn’t provide troubleshooting steps for failed data processing jobs.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Pantarhei > Running Jobs\n",
      "- Services > On-Premises > Pantarhei > Running Jobs > Accessing the Compute Nodes\n",
      "- Products > NGIAB 101 Learning Module > Model Execution\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: How do I optimize my computational resources?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Submit intensive work as Slurm jobs, not on shared login nodes.\n",
      "- Choose the appropriate queue (CPU, GPU, FPGA) matching your workload and walltime needs.\n",
      "- Use shared-node jobs for smaller workloads to improve throughput and utilization.\n",
      "- Keep jobs within standard limits (up to 240 cores). For larger needs, consult CIROH support.\n",
      "- For long runs, use queues allowing up to 7-day jobs (up to six full nodes).\n",
      "- On Pantarhei, use interactive SLURM sessions to prepare/run workflows and verify Singularity for containerized runs.\n",
      "- Leverage ACCESS program resources to supplement CIROH capacity when you need more compute or storage.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Pantarhei > Running Jobs > Accessing the Compute Nodes\n",
      "- Services > External Resources\n",
      "- Products > NGIAB 101 Learning Module > Advanced Topics\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: I need help with processing large datasets—where do I start?\n",
      "\n",
      "✅ Final Answer:\n",
      "You can start with two CIROH resources:\n",
      "\n",
      "- Research DataStream: A cloud-based, community-editable pipeline on AWS S3 for daily NextGen simulations and metadata. Browse data at datastream.ciroh.org, and use DataStreamCLI to automate input collection, NextGen execution (via NGIAB), and output handling. It supports multi-process runs and integrates hfsubset and TEEHR. Documentation covers models, options, directory standards, and usage, with an example workflow from hydrofabric acquisition to a 24-hour NextGen run.\n",
      "\n",
      "- Wukong HPC + Amazon S3: For very large-scale workflows, Wukong provides GPU-rich, multi-node computation integrated with S3’s durable, versioned storage. It accelerates training/execution of differentiable and process-based hydrologic models, national-scale routing, and NextGen model runs with data assimilation.\n",
      "\n",
      "If you’re setting up locally, follow the NGIAB Installation and Setup tutorial to deploy Docker-based NextGen environments, run sample datasets, and scale to parallel execution; it includes troubleshooting and links to HPC usage, evaluation (TEEHR), and visualization.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > Research Datastream\n",
      "- Blog > Pennsylvania State University Researchers Leverage CIROH Cyberinfrastructure for Advanced Hydrological Modeling\n",
      "- Products > NGIAB 101 Learning Module > Installation and Setup\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 5: How do I report a bug or issue to CIROH IT support?\n",
      "\n",
      "✅ Final Answer:\n",
      "Use the GitHub Issues page to report bugs or request features. For direct support, contact CIROH via email or the CIROH Slack. If you can’t access forms or need help, email ciroh-it-admin@ua.edu.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Distributions > NGIAB-CloudInfra > Contact Us\n",
      "- DocuHub > Contributing to CIROH DocuHub\n",
      "- Services > On-Premises > Pantarhei > Obtaining an Account\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Data & Workflow Best Practices\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: What are the best practices for managing CIROH datasets?\n",
      "\n",
      "✅ Final Answer:\n",
      "I cannot answer with the information given. The context references that subsequent sections provide recommendations and best practices for data management, but those details are not included here.\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies\n",
      "- Policies > Data and Code Sharing\n",
      "- Policies > Data and Code Sharing > Policy and Guidance\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: How do I ensure reproducibility in my CIROH research?\n",
      "\n",
      "✅ Final Answer:\n",
      "I cannot answer with the information given. The provided context describes CIROH policies and expectations for open data/code and points to detailed guidance elsewhere, but it does not list specific reproducibility practices.\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies\n",
      "- Policies > Data and Code Sharing > Policy and Guidance\n",
      "- Policies > Data and Code Sharing\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: What tools are available for data visualization in CIROH?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Visualization and Analysis Tools page with links to Tethys-CSES (Community Streamflow Evaluation System)\n",
      "- CIROH Research Portal native apps: TethysDash, Water Data Explorer, SWEML, Grace Groundwater Tool, Snow Inspector, CSES for National Water Model evaluation\n",
      "- Proxied external tools via the portal: FIM Visualization Deck, OWP NWM Map Viewer, CIROH JupyterHub, HydroShare, NFFA APP\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > Visualization and Analysis Tools\n",
      "- Products > CIROH Research Portal\n",
      "- Products > Snow Sensing and Modeling Tools > Intro to Snow Observations Modeling Analysis\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: How do I convert between different hydrological data formats?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t answer that with the information given. The context mentions common formats (GeoPackage, JSON, NetCDF-4, YAML, tarballs) and related tools, but it doesn’t provide conversion steps or utilities for converting between them.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > Research Datastream\n",
      "- Products > NextGen In A Box > Intro to NGIAB > Glossary\n",
      "- Products > Hydrofabric\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Policies & Administration\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: What are CIROH’s usage policies?\n",
      "\n",
      "✅ Final Answer:\n",
      "I cannot answer with the information given. The provided context describes CIROH’s data and code sharing policies and guidance, but it does not define “usage policies.”\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies\n",
      "- Policies > Data and Code Sharing > Policy and Guidance\n",
      "- Policies > Data and Code Sharing\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: How much compute time am I allocated?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t determine your compute time allocation from the provided information. The context describes job size/walltime limits (e.g., up to 7 days per job and queue constraints) and a default $500/month cloud budget, but not a per-user compute time allocation.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Pantarhei > Running Jobs > Accessing the Compute Nodes\n",
      "- Services > On-Premises > Wukong > System Architecture\n",
      "- Services > Public Cloud > CIROH Google Account\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: What are the CIROH data sharing policies?\n",
      "\n",
      "✅ Final Answer:\n",
      "CIROH follows an open data and open science policy aligned with NOAA’s Data Sharing Directive (v3.0). Key points:\n",
      "- Applies to CIROH awardees, sub-recipients, and contractors.\n",
      "- Environmental data must be machine-readable, openly documented, and accessible at no or minimal cost.\n",
      "- Include quality control with described methods.\n",
      "- Make data public by article publication, or within two years of collection or grant end (whichever comes first).\n",
      "- Use a specific NOAA disclaimer and provide data citation with DOIs.\n",
      "- Acknowledge funding (including FundRef).\n",
      "- Deposit final accepted manuscripts in the NOAA Institutional Repository (one-year embargo allowed).\n",
      "- Policy clarifies scope/exclusions and aligns with NOAA Information Quality Guidelines and NAO 212-15.\n",
      "- CIROH’s Data Management Plan serves as the implementation appendix.\n",
      "- The policy page is a living document with detailed guidance, partner agency requirements, and instructions for high-quality data and code publication.\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies > Data and Code Sharing\n",
      "- Policies > Data and Code Sharing > Policy and Guidance\n",
      "- Policies\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: Are there restrictions on using CIROH resources for commercial work?\n",
      "\n",
      "✅ Final Answer:\n",
      "I cannot answer with the information given. The provided context does not mention restrictions on using CIROH resources for commercial work.\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies > Data and Code Sharing > Policy and Guidance\n",
      "- Policies\n",
      "- Policies > Data and Code Sharing > Recommendations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop for RAG Pipeline (searching in TBLURLs only) with new dictionary structure\n",
    "verbose = False\n",
    "for topic, question_list in questions.items():\n",
    "    print(f\"\\n=============================================\")\n",
    "    print(f\"TOPIC: {topic}\")\n",
    "    print(f\"=============================================\\n\")\n",
    "    \n",
    "    for i, question in enumerate(question_list):\n",
    "        print(f\"--- \\n\\n❓ PROCESSING QUESTION {i+1}: {question}\\n\")\n",
    "            \n",
    "        # 1. Get the embedding for the current question\n",
    "        question_embedding = get_embedding(question, dimensions=1792)\n",
    "            \n",
    "        if question_embedding is None:\n",
    "            print(\"Could not generate embedding for the question. Skipping.\")\n",
    "            continue\n",
    "                \n",
    "        # 2. Query the database to get relevant context\n",
    "        retrieved_context = query_embedding(question_embedding)\n",
    "            \n",
    "        if not retrieved_context:\n",
    "            print(\"No relevant context found in the database. Skipping.\")\n",
    "            continue\n",
    "                \n",
    "        # Extract just the summary texts for the prompt\n",
    "        context_ids = [row[0] for row in retrieved_context]\n",
    "        context_summaries = [row[1] for row in retrieved_context]\n",
    "\n",
    "        if verbose:\n",
    "            print(\"📚 Retrieved Context:\")\n",
    "            for summary in context_summaries:\n",
    "                print(f\"- {summary[:120]}...\") # Print a snippet of each summary\n",
    "            print()\n",
    "\n",
    "        source_breadcrumbs = []\n",
    "        for url_id in context_ids:\n",
    "            breadcrumb = get_breadcrumb(conn, url_id)\n",
    "            if breadcrumb:\n",
    "                source_breadcrumbs.append(breadcrumb)\n",
    "\n",
    "        # 3. Build the RAG prompt\n",
    "        rag_prompt = build_rag_prompt(question, context_summaries)\n",
    "            \n",
    "        # 4. Get the final answer from the LLM\n",
    "        final_answer = get_rag_answer(rag_prompt)\n",
    "            \n",
    "        if final_answer:\n",
    "            print(f\"✅ Final Answer:\\n{final_answer}\\n\")\n",
    "\n",
    "            if source_breadcrumbs:\n",
    "                print(\"🔗 Sources:\")\n",
    "                unique_trails = list(dict.fromkeys(source_breadcrumbs))\n",
    "                for trail in unique_trails:\n",
    "                    print(f\"- {trail}\")\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7226e24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "TOPIC: Getting Started & Navigation\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: What is CIROH DocuHub and how can I use it?\n",
      "\n",
      "✅ Final Answer:\n",
      "CIROH DocuHub is CIROH’s centralized gateway for documentation, services, and community resources supporting hydrologic research and operations. It links you to computing (e.g., CIROH-2i2c JupyterHub on Google Cloud, CIROH AWS, Google Cloud, Pantarhei HPC), product documentation (NextGen, Snow model, Tethys, NextGen In A Box), policies, training, blogs, and collaboration tools like the CIROH Research Portal.\n",
      "\n",
      "How to use it:\n",
      "- Browse services and resources (e.g., Google Cloud access and tools) at docs.ciroh.org.\n",
      "- Follow product and training documentation to run models, process data, and use apps.\n",
      "- Join community activities (e.g., NextGen office hours).\n",
      "- Contribute your project docs, tutorials, datasets, or presentations via the Contribute page linked on DocuHub.\n",
      "\n",
      "🔗 Sources:\n",
      "- DocuHub\n",
      "- Products > CIROH Research Portal\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: How do I get started with CIROH services?\n",
      "\n",
      "✅ Final Answer:\n",
      "Visit the CIROH Services “Get started”/Infrastructure Access page: https://docs.ciroh.org/docs/services/access/. From there you can request public cloud access (AWS/Google Cloud) and other resources. For help, join the monthly CyberInfrastructure and Community NextGen Office Hours by emailing ciroh-it-admin@ua.edu for the Teams link.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services\n",
      "- Services > Public Cloud > CIROH AWS Account\n",
      "- Products > NextGen In A Box > Cyberinfrastructure and Community NextGen Office Hours\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: Where can I find the getting started guide?\n",
      "\n",
      "✅ Final Answer:\n",
      "The NGIAB 101 learning module: https://docs.ciroh.org/training-NGIAB-101/\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Intro to NGIAB > Installing NGIAB Locally\n",
      "- Products > NextGen In A Box > Intro to NGIAB\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: How do I become a CIROH consortium member?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t answer with the information given. The provided pages describe services and access for existing CIROH members and partners but do not explain how to become a consortium member.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Pantarhei > Obtaining an Account\n",
      "- Services\n",
      "- Services > Public Cloud > CIROH AWS Account\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Account & Access Requests\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: How do I request access to CIROH infrastructure?\n",
      "\n",
      "✅ Final Answer:\n",
      "- For project/team access: PIs/workshop leads submit the appropriate GitHub request:\n",
      "  - Cloud/JupyterHub: Cloud Infrastructure Request Form (GitHub template).\n",
      "  - On-prem HPC (Pantarhei/Wukong) and JetStream2 allocation: On-Premises Infrastructure Request Form (GitHub template).\n",
      "\n",
      "- For individual access:\n",
      "  - CIROH-2i2c JupyterHub: submit CPU or GPU Access Request Form (GitHub username required). For custom software, submit the Software Install Form with environment.yml.\n",
      "  - On-prem HPC: after your PI’s on-prem request is approved, submit the On-Premise Access Request Form. Non-UA users must complete the VPN section first.\n",
      "  - JetStream2: after PI submits the on-prem GitHub request, register for an NSF Access ID, then submit the JetStream2 Access Request Form.\n",
      "\n",
      "- For NWM BigQuery API: submit the NWM BigQuery API Access Request Form.\n",
      "\n",
      "If you have issues with JetStream2 forms, email ciroh-it-admin@ua.edu.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Infrastructure Access\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: What are the requirements for using CIROH resources?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t answer with the information given. The provided context describes CIROH’s data/code sharing policy and the CIROH CyberInfrastructure offerings and goals, but it does not state specific requirements for using CIROH resources.\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies > Data and Code Sharing > Policy and Guidance\n",
      "- Services\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: How do I request a new CIROH account?\n",
      "\n",
      "✅ Final Answer:\n",
      "You have two options, depending on what you need:\n",
      "\n",
      "- Pantarhei (on‑prem HPC) access:\n",
      "  1) Project PI submits the On-Premises Infrastructure Request (GitHub issue template).\n",
      "  2) Each user submits the On-Premise Access Request (Microsoft Form).\n",
      "  - UA users: submit only the On-Premise Access Request.\n",
      "  - Non‑UA users: first obtain VPN access, then submit the On-Premise Access Request.\n",
      "  - If forms are inaccessible, email ciroh-it-admin@ua.edu.\n",
      "\n",
      "- Public cloud (AWS or Google Cloud) subaccounts:\n",
      "  - Request via the Infrastructure Access workflow referenced on the CIROH docs pages:\n",
      "    • AWS: follow “Accessing Public Cloud Services” on the Infrastructure Access page.\n",
      "    • Google Cloud: same path via Infrastructure Access.\n",
      "  - Default budget is $500/month per project across AWS and Google Cloud; request additional funds via the Exceeding Budget Request Form if needed.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Pantarhei > Obtaining an Account\n",
      "- Services > Public Cloud > CIROH AWS Account\n",
      "- Services > Public Cloud > CIROH Google Account\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: How do I submit a request for new software installation?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Fill out the JupyterHub (2i2c) Software Install Form and select “Install Software on CIROH 2i2c JupyterHub” as the reason.\n",
      "- Export your conda environment to environment.yml:\n",
      "  - conda env export -n ENVNAME > environment.yml\n",
      "- Email the environment.yml to ciroh-it-support@ua.edu.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial > Request custom images\n",
      "- Services > On-Premises > Pantarhei > Obtaining an Account\n",
      "- Services > CIROH Subdomain Request Form\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 5: How do I request access to JupyterHub?\n",
      "\n",
      "✅ Final Answer:\n",
      "For CIROH-2i2c JupyterHub: Go to the Infrastructure Access page (https://docs.ciroh.org/docs/services/access#accessing-ciroh-2i2c-jupyterhub) and follow the access process. If using a workshop hub, ask your workshop coordinator for login details.\n",
      "\n",
      "For CUAHSI JupyterHub: Join the CUAHSI JupyterHub Group via HydroShare. After admission, launch from the HydroShare Apps library or Open with menu, or go to jupyterhub.cuahsi.org and log in with your HydroShare account. For help: help@cuahsi.org.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH JupyterHub\n",
      "- Services > Public Cloud > CUAHSI JupyterHub\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial > Request custom images\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 6: How do I request GPU access for research?\n",
      "\n",
      "✅ Final Answer:\n",
      "- For CIROH-2i2c JupyterHub (cloud): Submit the CIROH-2i2c JupyterHub GPU Access Request Form and include your GitHub username.\n",
      "- For on-prem HPC (Pantarhei/Wukong): Your PI must first submit the On-Premises Infrastructure Request Form. Then submit the On-Premise Access Request Form yourself (non-UA users must obtain VPN access first via the same form).\n",
      "\n",
      "If you can’t access the forms, email ciroh-it-admin@ua.edu.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Pantarhei > Obtaining an Account\n",
      "- Services > Infrastructure Access\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 7: How do I request AWS or Google Cloud access through CIROH?\n",
      "\n",
      "✅ Final Answer:\n",
      "Request access via the Infrastructure Access page’s “Accessing Public Cloud Services” section. CIROH will create AWS/Google Cloud subaccounts and PI identities (IAM). You can review past submissions on GitHub (AWS: https://github.com/CIROH-UA/NGIAB-CloudInfra/issues?q=is%3Aissue+is%3Aclosed+label%3Aaws, Google: https://github.com/CIROH-UA/NGIAB-CloudInfra/issues?q=is:issue+is:closed+label:google). If you expect to exceed the default $500/month shared budget, submit an Exceeding Budget Request using the provided GitHub issue template. For help, contact the CIROH IT admin email or Slack channel.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH Google Account\n",
      "- Services > Public Cloud > CIROH AWS Account\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 8: How do I request access to the Pantarhei or Wukong HPC clusters?\n",
      "\n",
      "✅ Final Answer:\n",
      "Pantarhei:\n",
      "- Step 1 (project): PI submits the On-Premises Infrastructure Request GitHub issue with project details: https://github.com/CIROH-UA/NGIAB-CloudInfra/issues/new?assignees=&labels=on-prem&projects=&template=onprem-request.md&title=\n",
      "- Step 2 (individual): Each user submits the On-Premise Access Request form: https://forms.office.com/Pages/ResponsePage.aspx?id=jnIAKtDwtECk6M5DPz-8p4IIpHdEnmhNgjOa9FjrwGtUMzdTOUpKVU5UWFNCU0ZQUlowS0cxV0xFRy4u\n",
      "- UA users: submit only the On-Premises Access Request. External users: request VPN access first, then submit the On-Premises Access Request.\n",
      "- If forms are inaccessible: email ciroh-it-admin@ua.edu.\n",
      "\n",
      "Wukong:\n",
      "- Step 1 (project): PI submits the On‑premises Infrastructure Request GitHub issue with PI info and a roster (full names, GitHub usernames, and affiliated emails): https://github.com/CIROH-UA/NGIAB-CloudInfra/issues/new?assignees=&labels=on-prem&projects=&template=onprem-request.md&title=\n",
      "- Step 2 (individual): Each user submits the CIROH On‑Premise Access Form: https://forms.office.com/r/hED4zGVACM\n",
      "- External (non‑UA) users: complete VPN Access Request via the same form workflow before the On‑Premise Access Request.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Wukong > Obtaining an Account\n",
      "- Services > On-Premises > Pantarhei > Obtaining an Account\n",
      "- Services > On-Premises > Pantarhei > Accessing the System\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 9: How do I request access to the NWM BigQuery API?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Fill out the NWM BigQuery API Access Request Form: https://forms.office.com/r/FeNpjZstkr\n",
      "- After approval, use the API at https://nwm-api.ciroh.org (docs: https://nwm-api.ciroh.org/docs).\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > Data Management and Access Tools > NWM BigQuery API\n",
      "- Services > Public Cloud > CIROH Google Account\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Documentation & Training\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: Where can I find NextGen framework documentation?\n",
      "\n",
      "✅ Final Answer:\n",
      "- NextGen Technical Guidance page: https://docs.ciroh.org/docs/policies/NextGen (with link to full PDF)\n",
      "- NextGen framework overview/presentation: https://docs.ciroh.org/docs/products/nextgen-framework/nextgen/\n",
      "- NextGen In A Box (NGIAB) intro/getting started: https://docs.ciroh.org/docs/products/ngiab/intro/ and https://docs.ciroh.org/docs/products/ngiab/intro/what-is\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies > NextGen Framework\n",
      "- Products > National Water Model > NextGen Framework\n",
      "- Products > NextGen In A Box > Distributions > NGIAB-CloudInfra > Getting Started\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: Where can I find documentation for a specific CIROH tool?\n",
      "\n",
      "✅ Final Answer:\n",
      "Use the Documentation section on the CIROH DocuHub: https://docs.ciroh.org/docs/products/intro\n",
      "\n",
      "🔗 Sources:\n",
      "- DocuHub\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: Where can I access tutorials and training materials?\n",
      "\n",
      "✅ Final Answer:\n",
      "Use the NGIAB 101 training module and the Learner Profiles page. NGIAB 101 links to source code on GitHub, core docs on CIROH Docs, quick-start paths, Key Points, a Glossary, and external Bash/Git tutorials. The Learner Profiles page routes you to audience-specific NGIAB training (general, HPC, or DevCon 2025 Jetstream instructions with troubleshooting).\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NGIAB 101 Learning Module > Learner Profiles\n",
      "- Products > NGIAB 101 Learning Module\n",
      "- Products > NGIAB 101 Learning Module > Instructor - Summary and Schedule > Instructor Notes\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: What educational resources are available for CIROH users?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Educational courses via the CIROH Research Portal (integrated with HydroLearn)\n",
      "- Documentation on CIROH products (e.g., NextGen, Snow model, Tethys) in the DocuHub\n",
      "- Training materials, tutorials, and contribution guides via the DocuHub contribute page\n",
      "- Interactive learning modules and web apps accessible through the CIROH Portal\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > CIROH Research Portal\n",
      "- DocuHub\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Contributing Content\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: How do I contribute to CIROH DocuHub?\n",
      "\n",
      "✅ Final Answer:\n",
      "You can contribute by adding product/project documentation, tutorials, training data, or conference presentations. Visit the “How to Contribute?” page for instructions and repository access: https://docs.ciroh.org/docs/contribute. You can also share feedback here: https://forms.office.com/r/5ww7qRWwwf.\n",
      "\n",
      "🔗 Sources:\n",
      "- DocuHub\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: How do I add my project documentation?\n",
      "\n",
      "✅ Final Answer:\n",
      "You can add documentation in two ways:\n",
      "\n",
      "- Minor edits to existing pages: click “Edit page” on docs.ciroh.org, make changes, and submit a pull request. Admins will review and merge.\n",
      "- New/major content: fork the GitHub repo (CIROH-UA/ciroh-ua_website), add your docs (Markdown/Docusaurus), commit, and open a pull request. GitHub Actions will build/publish after review.\n",
      "\n",
      "If your project is a product you want listed, ensure it has a public GitHub repo with a clear README and submit a Product Page request via the dedicated GitHub issue template.\n",
      "\n",
      "Support: Slack, ciroh-it-admin@ua.edu, or the site’s contact page.\n",
      "\n",
      "🔗 Sources:\n",
      "- DocuHub > Contributing to CIROH DocuHub\n",
      "- DocuHub > Contributing to CIROH DocuHub > Working with the DocuHub repository\n",
      "- DocuHub > Contributing to CIROH DocuHub > DocuHub technologies\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: Where do I submit tutorials or training materials?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t determine that from the provided information.\n",
      "\n",
      "🔗 Sources:\n",
      "- DocuHub > Contributing to CIROH DocuHub > Working with the DocuHub repository\n",
      "- DocuHub > Contributing to CIROH DocuHub\n",
      "- Products > NGIAB 101 Learning Module > Advanced Topics\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: How do I publish my research findings on DocuHub?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t answer with the information given. The page says consortium members can contribute documentation, tutorials, training data, and presentations, and links to “How to Contribute?” at https://docs.ciroh.org/docs/contribute for publishing details.\n",
      "\n",
      "🔗 Sources:\n",
      "- DocuHub\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Services & Infrastructure: JupyterHub\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: How do I access CIROH JupyterHub?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Request access via CIROH’s Infrastructure Access process: https://docs.ciroh.org/docs/services/access#accessing-ciroh-2i2c-jupyterhub\n",
      "- If you’re in a workshop, get login details from your workshop coordinator.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH JupyterHub\n",
      "- Services > Public Cloud > HydroShare and CIROH JupyterHub Integration\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: What’s the difference between Production, Staging, and Workshop JupyterHub?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Production: Main CIROH-2i2c JupyterHub for everyday research use.\n",
      "- Staging: Test/pre-release environment separate from production.\n",
      "- Workshop: Temporary hub activated only during specific conferences/programs.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH JupyterHub\n",
      "- Services > Public Cloud > CUAHSI JupyterHub\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: What software is pre-installed on JupyterHub?\n",
      "\n",
      "✅ Final Answer:\n",
      "Please refer to the awi-ciroh-image Dockerfile for the current list of pre-installed software:\n",
      "- https://github.com/2i2c-org/awi-ciroh-image/blob/main/Dockerfile\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH JupyterHub\n",
      "- Services > Public Cloud > CUAHSI JupyterHub\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: How do I stop my JupyterHub server when I’m not using it?\n",
      "\n",
      "✅ Final Answer:\n",
      "The docs emphasize stopping servers when idle but don’t provide exact steps. I can’t answer how to stop it with the information given.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial > Prevent Server Timeout\n",
      "- Services > Public Cloud > CIROH JupyterHub\n",
      "- Services > Public Cloud > CUAHSI JupyterHub\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 5: How do I install custom software on JupyterHub?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Check the current software list in the CIROH JupyterHub Dockerfile.\n",
      "- Export your conda environment: conda env export -n ENVNAME > environment.yml\n",
      "- Submit the JupyterHub (2i2c) Software Install Form and select “Install Software on CIROH 2i2c JupyterHub.”\n",
      "- Email your environment.yml to ciroh-it-support@ua.edu.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial > Request custom images\n",
      "- Services > Public Cloud > CIROH JupyterHub\n",
      "- Services > Public Cloud > CIROH JupyterHub > Documentation and Tutorial > Push and Pull to GitHub\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Services & Infrastructure: Cloud & HPC\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: How do I request AWS cloud credits through CIROH?\n",
      "\n",
      "✅ Final Answer:\n",
      "Use the Infrastructure Access workflow to request a CIROH AWS subaccount and access. Projects receive $500/month shared across AWS and Google Cloud by default. If you expect to exceed this, submit the Exceeding Budget Request Form via the provided GitHub issue template: https://github.com/CIROH-UA/NGIAB-CloudInfra/issues/new?assignees=&labels=infrastructure&projects=&template=exceeding_budget_request.md&title=\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CIROH AWS Account\n",
      "- Services > Public Cloud > CIROH Google Account\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: What computing resources does CIROH offer?\n",
      "\n",
      "✅ Final Answer:\n",
      "CIROH offers a multi-cloud and on-premise CyberInfrastructure, including:\n",
      "- AWS services\n",
      "- Google Cloud services\n",
      "- Pantarhei on-premise HPC cluster\n",
      "- Managed JupyterHub service (2i2c on GCP)\n",
      "It also points members to external NSF ACCESS advanced computing resources.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services\n",
      "- Services > External Resources\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: How do I use the Pantarhei HPC cluster?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Obtain a Pantarhei account and review UA policies from the Pantarhei landing page.\n",
      "- Connect to the UA network via VPN (see UA OIT VPN instructions).\n",
      "- Log in via SSH using your SSH keys:\n",
      "  - Open a terminal and run: ssh <USERNAME>@pantarhei.ua.edu, then enter your Pantarhei password.\n",
      "- Do not run intensive work on the login node. Submit workloads as Slurm jobs to appropriate queues (CPU, GPU, or FPGA).\n",
      "- Queue notes:\n",
      "  - Shared-node jobs are supported to improve throughput.\n",
      "  - Long jobs up to 7 days are allowed for up to 6 full nodes.\n",
      "  - Standard maximum job size is 240 cores; request larger via a support consultation.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Pantarhei > Running Jobs > Accessing the Compute Nodes\n",
      "- Services > On-Premises > Pantarhei > Accessing the System\n",
      "- Services > On-Premises > Pantarhei\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: How do I access JetStream2?\n",
      "\n",
      "✅ Final Answer:\n",
      "To access JetStream2 through CIROH:\n",
      "\n",
      "1) Your project PI submits the Infrastructure Request Form: https://github.com/CIROH-UA/NGIAB-CloudInfra/issues/new?assignees=&labels=on-prem&projects=&template=onprem-request.md&title=\n",
      "2) If you don’t have one, create an NSF Access account: https://operations.access-ci.org/identity/new-user\n",
      "3) With your NSF Access ID, submit the JetStream2 Access Request Form: https://forms.office.com/r/ERyKyHbdaC\n",
      "\n",
      "If you can’t access the forms, email ciroh-it-admin@ua.edu. After approval, follow the JetStream2 login guide: https://docs.jetstream-cloud.org/getting-started/login/\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > External Resources > NSF Access > JetStream2\n",
      "- Services > Infrastructure Access\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 5: How do I request compute resources for a workshop or training?\n",
      "\n",
      "✅ Final Answer:\n",
      "Use the Workshop IT Request process:\n",
      "1) Complete the GitHub workshop template with your technical requirements.\n",
      "2) The CIROH team will process it and ensure participants have access before the event.\n",
      "\n",
      "Link: https://github.com/CIROH-UA/NGIAB-CloudInfra/issues/new?assignees=&projects=&template=workshop_IT_request.md\n",
      "\n",
      "🔗 Sources:\n",
      "- Blog > DevCon 2025: A DevOps and Cyberinfrastructure Success Story\n",
      "- Services > Infrastructure Access\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Services & Infrastructure: Data Access\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: How do I access the AORC dataset?\n",
      "\n",
      "✅ Final Answer:\n",
      "You can access AORC via the user-friendly Jupyter notebooks provided:\n",
      "\n",
      "- Go to the HydroShare resource: https://www.hydroshare.org/resource/72ea9726187e43d7b50a624f2acf591f/\n",
      "- Click “Open With” (top right) and choose “CIROH 2i2c JupyterHub.” This copies the notebooks into your JupyterHub.\n",
      "- Open the appropriate notebook (point or polygon; lat–lon or NWM projection) to retrieve and aggregate AORC data from AWS, subset spatially, and aggregate temporally.\n",
      "\n",
      "Requirements:\n",
      "- CUAHSI HydroShare account\n",
      "- CIROH-2i2c JupyterHub access via a GitHub account: https://docs.ciroh.org/docs/services/access/#accessing-ciroh-2i2c-jupyterhub\n",
      "\n",
      "Development notebooks are also on GitHub: https://github.com/CUAHSI/notebooks (Data Access Examples / AORC).\n",
      "\n",
      "🔗 Sources:\n",
      "- Blog > AORC Data in Your Hands: User-Friendly Jupyter Notebooks for Data Retrieval and Analysis via CIROH JupyterHub Notebooks\n",
      "- Products > Data Management and Access Tools > Data Access\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: Where can I find forcing data for hydrological models?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Research DataStream forcings: datastream.ciroh.org/index.html (AWS S3 browser)\n",
      "- NWM forcings via NOMADS: https://nomads.ncep.noaa.gov/pub/data/nccf/com/nwm\n",
      "- NWM forcings in cloud:\n",
      "  - AWS/NODD\n",
      "  - Google Cloud: https://console.cloud.google.com/storage/browser/national-water-model\n",
      "  - Azure/Planetary Computer: https://planetarycomputer.microsoft.com/dataset/storage/noaa-nwm\n",
      "- CIROH Kerchunk catalogs (Zarr/NetCDF pointers):\n",
      "  - Retrospective: https://ciroh-nwm-zarr-retrospective-data-copy.s3.amazonaws.com/index.html\n",
      "  - Operational: https://ciroh-nwm-zarr-copy.s3.amazonaws.com/index.html\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > Research Datastream\n",
      "- Products > Data Management and Access Tools > Data Access\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: How do I retrieve data for a specific region?\n",
      "\n",
      "✅ Final Answer:\n",
      "Use the AORC_LL_ZoneRetrieval.ipynb (lat–lon) or AORC_NWMProj_ZoneRetrieval.ipynb (NWM projection) notebook from the HydroShare resource. Open the resource in HydroShare, click “Open With” → “CIROH 2i2c JupyterHub” to copy into JupyterHub, then follow the notebook to provide your polygon shapefile, subset spatially over your region, and aggregate over your desired time intervals. Requires a HydroShare account and CIROH-2i2c JupyterHub access via GitHub.\n",
      "\n",
      "🔗 Sources:\n",
      "- Blog > AORC Data in Your Hands: User-Friendly Jupyter Notebooks for Data Retrieval and Analysis via CIROH JupyterHub Notebooks\n",
      "- Products > Data Management and Access Tools > Data Access\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: What data formats are supported by CIROH?\n",
      "\n",
      "✅ Final Answer:\n",
      "I cannot answer with the information given. The provided context does not list supported data formats.\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies\n",
      "- Policies > Data and Code Sharing > Policy and Guidance\n",
      "- Products > CIROH Research Portal\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: NextGen Framework\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: How do I get started with the NextGen framework?\n",
      "\n",
      "✅ Final Answer:\n",
      "Start with NGIAB (NextGen In A Box), which containerizes NextGen to simplify setup and provide a consistent, reproducible environment.\n",
      "\n",
      "- New users: take the NGIAB 101 training module: https://docs.ciroh.org/training-NGIAB-101/\n",
      "- Then follow the installation/start guide: https://docs.ciroh.org/docs/products/ngiab/intro/install or the quick start section linked from Getting Started.\n",
      "- For orientation, use the Intro to NGIAB hub: https://docs.ciroh.org/docs/products/ngiab/intro/ (overview, capabilities, glossary, run directory structure).\n",
      "\n",
      "NGIAB leverages BMI for interoperable, multi-BMI module formulations and aligns with future National Water Model modernization.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Distributions > NGIAB-CloudInfra > Getting Started\n",
      "- Products > National Water Model > NextGen Framework\n",
      "- Products > NextGen In A Box > Intro to NGIAB\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: What is NextGen In A Box (NGIAB)?\n",
      "\n",
      "✅ Final Answer:\n",
      "NextGen In A Box (NGIAB) is a containerized distribution of the NextGen hydrologic modeling framework. It standardizes the operating system, dependencies, and runtime so NextGen (including the NWM v3.0 configuration) can be installed and run reproducibly across platforms in about 30 minutes. NGIAB also bundles open-source tools for customizing, evaluating, and visualizing model runs, improving accessibility, interoperability, and reproducibility.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Intro to NGIAB > NWM, NextGen, and NGIAB\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: How do I run NextGen locally?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Install prerequisites:\n",
      "  - Windows: Install WSL, install and start Docker Desktop, open WSL as Admin, run docker ps -a to verify. Ensure you use a non-Docker-linked WSL distro.\n",
      "  - Mac: Install and start Docker Desktop, run docker ps -a to verify.\n",
      "- Create a project directory:\n",
      "  - (WSL example) cd /mnt/c/Users/<Folder>; mkdir -p NextGen; cd NextGen\n",
      "- Download sample data:\n",
      "  - mkdir -p ngen-data; cd ngen-data\n",
      "  - wget https://ciroh-ua-ngen-data.s3.us-east-2.amazonaws.com/AWI-009/AWI_16_10154200_009.tar.gz\n",
      "  - tar -xf AWI_16_10154200_009.tar.gz\n",
      "  - cd ..\n",
      "- Clone and run NGIAB-CloudInfra:\n",
      "  - (WSL: ensure Git uses LF, not CRLF)\n",
      "  - git clone https://github.com/CIROH-UA/NGIAB-CloudInfra.git\n",
      "  - cd NGIAB-CloudInfra\n",
      "  - ./guide.sh\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Intro to NGIAB > Installing NGIAB Locally\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: How do I configure NextGen for my basin?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t answer with the information given. The provided context explains what NextGen and NGIAB are and how modules are ordered via the run realization file, but it does not include basin-configuration steps. Please consult the NGIAB “Getting Started” and Intro pages linked in the context for installation and configuration guidance.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Distributions > NGIAB-CloudInfra > Getting Started\n",
      "- Products > National Water Model > NextGen Framework\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 5: How do I troubleshoot NextGen setup issues?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t answer with the information given. The context only notes that NGIAB setup can be difficult and points to the NGIAB 101 training module for troubleshooting (including WSL line-ending issues) and to run ./guide.sh to validate a local setup. For specific troubleshooting steps, please refer to the NGIAB 101 training module.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Distributions > NGIAB-CloudInfra > Getting Started\n",
      "- Products > NextGen In A Box > Distributions > NGIAB-CloudInfra > Contact Us\n",
      "- Products > NextGen In A Box > Intro to NGIAB > Installing NGIAB Locally\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 6: My NextGen model isn’t running—what should I check?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Ensure your run directory follows the required structure: ngen-run/ with subfolders config (required), forcings (required), outputs (required), metadata (auto-generated), and optional lakeout/restart.\n",
      "- Verify config contains:\n",
      "  - realization.json defining models, run parameters (dates/times), and hydrofabric specs.\n",
      "  - A single hydrofabric geopackage (e.g., nextgen_09.gpkg).\n",
      "  - Any required BMI configs and per-catchment configs under config/cat-config (e.g., PET/, CFE/, NOAH-OWP-M/), matching what the realization references.\n",
      "- Confirm forcings exist for all required catchments and include needed variables (e.g., wind, temperature, precipitation, solar radiation).\n",
      "- Check that module execution order in the realization file is correct for your multi-BMI formulation.\n",
      "- Do not edit the metadata folder; allow ngen to generate it.\n",
      "- If you used NGIAB, rebuild the run directory with the Data Preprocess tool to ensure all required files are present and correctly organized.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > National Water Model > NextGen Framework\n",
      "- Products > NextGen In A Box > Distributions > NGIAB-CloudInfra > Getting Started\n",
      "- Products > NextGen In A Box > Intro to NGIAB > Run Configuration Directory Structure\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 7: How do I resolve dependency conflicts in NextGen?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t answer that with the information given. The provided pages describe the NextGen framework, technical guidance scope, and NGIAB containerization, but they do not include steps or recommendations for resolving dependency conflicts.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > National Water Model > NextGen Framework\n",
      "- Policies > NextGen Framework\n",
      "- Products > NextGen In A Box > Distributions > NGIAB-CloudInfra > Getting Started\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Community & Collaboration\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: How do I connect with other CIROH researchers?\n",
      "\n",
      "✅ Final Answer:\n",
      "Email ciroh-it-admin@ua.edu to join the monthly Cyberinfrastructure and Community NextGen Office Hours on Microsoft Teams, where you can engage with CIROH experts and other researchers.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Cyberinfrastructure and Community NextGen Office Hours\n",
      "- Products > CIROH Research Portal\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: How do I join CIROH office hours?\n",
      "\n",
      "✅ Final Answer:\n",
      "Email ciroh-it-admin@ua.edu to receive the Microsoft Teams meeting link and calendar invite and to subscribe to the monthly sessions.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Cyberinfrastructure and Community NextGen Office Hours\n",
      "- Services > Public Cloud > CIROH AWS Account > CIROH AWS Office Hours\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: How do I provide feedback on CIROH services?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t answer that with the information given. The provided pages describe services and policies but don’t include feedback instructions.\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies\n",
      "- Services\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Technical Support\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: I can’t access my JupyterHub environment—what should I do?\n",
      "\n",
      "✅ Final Answer:\n",
      "- CUAHSI JupyterHub: Ensure you’ve joined the CUAHSI JupyterHub Group via HydroShare and that your HydroShare profile is complete. Try launching from HydroShare Apps or “Open with.” If still blocked, email help@cuahsi.org.\n",
      "- CIROH-2i2c JupyterHub: Make sure you have access via CIROH’s Infrastructure Access process and are using the correct hub (Production/Staging/Workshop). If issues persist, contact CIROH Cloud support (per CIROH channels) and ensure your server isn’t left running idle; stop/restart the server.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > Public Cloud > CUAHSI JupyterHub\n",
      "- Services > Public Cloud > CIROH JupyterHub\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: My data processing job failed—how can I troubleshoot?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t provide specific troubleshooting steps from the given information. The docs only note that Pantarhei uses Slurm and that you should submit work as Slurm jobs (not on login nodes), with queues and limits. \n",
      "\n",
      "General next steps within this context:\n",
      "- Check your Slurm job output and error files (e.g., slurm-<jobid>.out/.err) for messages.\n",
      "- Verify you submitted to an appropriate queue (CPU/GPU/FPGA) and within limits (walltime, cores ≤240, node counts, ≤7-day runs, shared-node vs full-node).\n",
      "- If your job exceeds standard limits or repeatedly fails at scale, open a consulting ticket with Pantarhei support.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Pantarhei > Running Jobs\n",
      "- Services > On-Premises > Pantarhei > Running Jobs > Accessing the Compute Nodes\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: How do I optimize my computational resources?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Submit all intensive work as Slurm jobs instead of running on shared login nodes.\n",
      "- Choose appropriate queues (CPU, GPU, FPGA) that match your workload; shorter walltime/smaller job size queues can yield faster turnaround.\n",
      "- Use shared-node jobs when possible to increase throughput and system utilization.\n",
      "- For long workflows, leverage long-running jobs (up to 7 days on as many as 6 full nodes).\n",
      "- Keep standard jobs within 240 cores; if you need more, open a consulting ticket with Pantarhei support.\n",
      "- If you need additional capacity beyond CIROH resources, consider NSF ACCESS computing and storage resources at no cost.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Pantarhei > Running Jobs > Accessing the Compute Nodes\n",
      "- Services > External Resources\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: I need help with processing large datasets—where do I start?\n",
      "\n",
      "✅ Final Answer:\n",
      "Start with DataStreamCLI. Steps:\n",
      "- Install following the Installation Guide.\n",
      "- Run the interactive DataStreamCLI guide script to learn options and form a command.\n",
      "- Review docs for Datastream options, NextGen models, directory standards, and usage.\n",
      "- Use hfsubset to obtain a hydrofabric geopackage for your area.\n",
      "- Execute DataStreamCLI with your time range, configuration, data directory, geopackage, and process count; outputs will be written under your specified data directory.\n",
      "- For browsing existing large forcings and outputs, use the AWS S3 Explorer at datastream.ciroh.org.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > Research Datastream\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 5: How do I report a bug or issue to CIROH IT support?\n",
      "\n",
      "✅ Final Answer:\n",
      "Use the NGIAB CloudInfra GitHub issue tracker to report bugs or feature requests: https://github.com/CIROH-UA/NGIAB-CloudInfra/issues. For guidance, see the contribution guide: https://github.com/CIROH-UA/NGIAB-CloudInfra/blob/main/docs/05_CONTRIBUTE.md. You can also email ciroh-it-admin@ua.edu or reach out on the CIROH Slack #ciroh-ua-it-support channel (workspace access required).\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > NextGen In A Box > Distributions > NGIAB-CloudInfra > Contact Us\n",
      "- Services > On-Premises > Pantarhei > Obtaining an Account\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Data & Workflow Best Practices\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: What are the best practices for managing CIROH datasets?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t answer that with the information given. The provided pages introduce CIROH’s policies and cite NOAA-aligned requirements, but they don’t list specific best practices for managing CIROH datasets.\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies\n",
      "- Policies > Data and Code Sharing\n",
      "- Policies > Data and Code Sharing > Policy and Guidance\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: How do I ensure reproducibility in my CIROH research?\n",
      "\n",
      "✅ Final Answer:\n",
      "Follow CIROH’s guiding principles: make your science open and reproducible by:\n",
      "- Sharing data and code openly in machine-readable, preferably open-standard formats.\n",
      "- Providing sufficient metadata and documentation (include QC methods and results in metadata).\n",
      "- Making products publicly accessible on time (by article publication or within two years, whichever is sooner), with required NOAA disclaimer and proper citations/acknowledgments.\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies\n",
      "- Policies > Data and Code Sharing > Policy and Guidance\n",
      "- Policies > Data and Code Sharing\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: What tools are available for data visualization in CIROH?\n",
      "\n",
      "✅ Final Answer:\n",
      "- Tethys-CSES (Community Streamflow Evaluation System) web application\n",
      "- CIROH Research Portal native apps: TethysDash, Water Data Explorer, SWEML, Grace Groundwater Tool, Snow Inspector, CSES (NWM evaluation)\n",
      "- Proxy apps accessible via the portal: FIM Visualization Deck, OWP NWM Map Viewer, CIROH JupyterHub, HydroShare, NFFA APP\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > Visualization and Analysis Tools\n",
      "- Products > CIROH Research Portal\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: How do I convert between different hydrological data formats?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t answer with the information given. The provided context defines common formats used (GeoPackage, JSON, NetCDF-4, YAML, tarballs) and related tools (e.g., Hydrofabric R library, TEEHR, t-route) but does not describe conversion methods or workflows between formats.\n",
      "\n",
      "🔗 Sources:\n",
      "- Products > Research Datastream\n",
      "- Products > NextGen In A Box > Intro to NGIAB > Glossary\n",
      "- Products > Hydrofabric\n",
      "\n",
      "\n",
      "=============================================\n",
      "TOPIC: Policies & Administration\n",
      "=============================================\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 1: What are CIROH’s usage policies?\n",
      "\n",
      "✅ Final Answer:\n",
      "I cannot answer with the information given. The provided context summarizes CIROH’s data and code sharing policy and guiding principles but does not define “usage policies.”\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies\n",
      "- Policies > Data and Code Sharing > Policy and Guidance\n",
      "- Policies > Data and Code Sharing\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 2: How much compute time am I allocated?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t determine your specific compute time allocation from the provided information. The context describes queue limits (e.g., up to 7-day jobs, max 240 cores without consultation) but not per-user or project time quotas.\n",
      "\n",
      "🔗 Sources:\n",
      "- Services > On-Premises > Pantarhei > Running Jobs > Accessing the Compute Nodes\n",
      "- Services > On-Premises > Wukong > System Architecture\n",
      "- Services > Public Cloud > CIROH Google Account\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 3: What are the CIROH data sharing policies?\n",
      "\n",
      "✅ Final Answer:\n",
      "CIROH follows NOAA’s Data Sharing Directive (v3.0) and requires:\n",
      "\n",
      "- Public access: Environmental data collected/created under CIROH awards must be publicly visible and accessible at no or minimal cost, in machine-readable, preferably open formats, with sufficient, preferably open-standard metadata. Include the data’s internet location in the final report.\n",
      "- Quality control: Data should undergo QC; describe QC methods and results in the metadata per NOAA Information Quality Guidelines.\n",
      "- Timeliness: Make data accessible no later than the earlier of (a) publication of a peer‑reviewed article based on the data, (b) two years after data verification/collection, or (c) two years after the original grant end date, unless NOAA authorizes a delay.\n",
      "- Disclaimer: Include “These data and related items of information have not been formally disseminated by NOAA, and do not represent any agency determination, view, or policy.”\n",
      "- Enforcement: Failure or delay in sharing per the Data Management Plan may lead to enforcement actions and affect future award decisions; applies to sub-recipients and subcontractors.\n",
      "- Funding acknowledgment: Identify federal funding sources and include grant programs and award numbers in publications.\n",
      "- Manuscripts: Submit final accepted manuscripts to the NOAA Institutional Repository; a one-year embargo is permitted.\n",
      "- General principles: Emphasize reproducibility and openness; open access to data, code, and metadata; CIROH products are publicly funded and should be broadly accessible.\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies > Data and Code Sharing\n",
      "- Policies > Data and Code Sharing > Policy and Guidance\n",
      "- Policies\n",
      "\n",
      "--- \n",
      "\n",
      "❓ PROCESSING QUESTION 4: Are there restrictions on using CIROH resources for commercial work?\n",
      "\n",
      "✅ Final Answer:\n",
      "I can’t determine this from the provided information. The excerpts cover data/code sharing, timelines, licensing, and publication practices, but don’t address commercial-use restrictions for CIROH resources.\n",
      "\n",
      "🔗 Sources:\n",
      "- Policies > Data and Code Sharing > Policy and Guidance\n",
      "- Policies > Data and Code Sharing > Recommendations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RAG Pipeline Loop for knowledge searching in TBLURLs and TBLContent with new dictionary structure\n",
    "verbose = False\n",
    "for topic, question_list in questions.items():\n",
    "    print(f\"\\n=============================================\")\n",
    "    print(f\"TOPIC: {topic}\")\n",
    "    print(f\"=============================================\\n\")\n",
    "\n",
    "    for i, question in enumerate(question_list):\n",
    "        print(f\"--- \\n\\n❓ PROCESSING QUESTION {i+1}: {question}\\n\")\n",
    "            \n",
    "        # 1. Get the embedding for the current question\n",
    "        question_embedding = get_embedding(question, dimensions=1792)\n",
    "            \n",
    "        if question_embedding is None:\n",
    "            print(\"Could not generate embedding for the question. Skipping.\")\n",
    "            continue\n",
    "                \n",
    "        # --- LEVEL 1 SEARCH: Find relevant pages and their summaries ---\n",
    "        retrieved_pages = query_embedding(question_embedding)\n",
    "            \n",
    "        if not retrieved_pages:\n",
    "            print(\"No relevant pages found in the database. Skipping.\")\n",
    "            continue\n",
    "                \n",
    "        # Create a map of idurl -> summary from the initial results for efficient access\n",
    "        page_summary_map = {row[0]: row[1] for row in retrieved_pages}\n",
    "        context_ids = list(page_summary_map.keys())\n",
    "        if verbose:\n",
    "            print(f\"📚 Level 1: Found relevant pages with IDs: {context_ids}\")\n",
    "\n",
    "        # --- LEVEL 2 SEARCH: Find relevant chunks within those pages ---\n",
    "        retrieved_chunks = query_chunks(question_embedding, context_ids)\n",
    "\n",
    "        final_context_list = []\n",
    "        source_ids = []\n",
    "\n",
    "        if not retrieved_chunks:\n",
    "            # Fallback strategy: If no specific chunks are found, use the page summaries from Level 1\n",
    "            if verbose:\n",
    "                print(\"No specific chunks found, falling back to page summaries for context.\")\n",
    "            final_context_list = list(page_summary_map.values())\n",
    "            source_ids = context_ids\n",
    "        else:\n",
    "            # --- NEW LOGIC: Group chunks by page and build rich, multi-source context ---\n",
    "            if verbose:\n",
    "                print(f\"🎯 Level 2: Found {len(retrieved_chunks)} relevant chunks across pages.\")\n",
    "            \n",
    "            chunks_by_page = {}\n",
    "            for idurl, order, content in retrieved_chunks:\n",
    "                if idurl not in chunks_by_page:\n",
    "                    chunks_by_page[idurl] = []\n",
    "                chunks_by_page[idurl].append(order)\n",
    "\n",
    "            # Iterate through the original pages to maintain relevance order\n",
    "            for page_id in context_ids:\n",
    "                if page_id in chunks_by_page:\n",
    "                    source_ids.append(page_id)\n",
    "                    \n",
    "                    # Get the page summary from the map (no new DB call)\n",
    "                    page_summary = page_summary_map.get(page_id, \"No summary available.\")\n",
    "                    \n",
    "                    # Get the order numbers of relevant chunks for this page\n",
    "                    relevant_orders = chunks_by_page[page_id]\n",
    "                    \n",
    "                    # Expand to include neighbors and remove duplicates\n",
    "                    orders_with_neighbors = set()\n",
    "                    for order_num in relevant_orders:\n",
    "                        orders_with_neighbors.add(order_num - 1)\n",
    "                        orders_with_neighbors.add(order_num)\n",
    "                        orders_with_neighbors.add(order_num + 1)\n",
    "                    \n",
    "                    # Fetch all unique chunks (originals + neighbors) in correct document order\n",
    "                    expanded_chunk_rows = execute_query(conn, \"\"\"\n",
    "                        SELECT Content FROM TBLContent\n",
    "                        WHERE idurl = %s AND \"order\" = ANY(%s)\n",
    "                        ORDER BY \"order\" ASC;\n",
    "                    \"\"\", params=(page_id, list(orders_with_neighbors)), fetch=True)\n",
    "                    \n",
    "                    if expanded_chunk_rows:\n",
    "                        detailed_context = \"\\n\\n\".join([row[0] for row in expanded_chunk_rows])\n",
    "                        \n",
    "                        # Combine summary and detailed context for this page\n",
    "                        page_context = f\"Source Page Summary:\\n{page_summary}\\n\\nDetailed Information from this page:\\n{detailed_context}\"\n",
    "                        final_context_list.append(page_context)\n",
    "\n",
    "        if not final_context_list:\n",
    "            print(\"Could not build any context. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\n📝 Final Combined Context for LLM:\")\n",
    "            for idx, ctx in enumerate(final_context_list):\n",
    "                print(f\"--- Context Block {idx+1} ---\\n{ctx[:10000]}...\\n\")\n",
    "\n",
    "        # 3. Build the RAG prompt with the new, multi-source context\n",
    "        rag_prompt = build_rag_prompt(question, final_context_list)\n",
    "            \n",
    "        # 4. Get the final answer from the LLM\n",
    "        final_answer = get_rag_answer(rag_prompt)\n",
    "            \n",
    "        if final_answer:\n",
    "            print(f\"✅ Final Answer:\\n{final_answer}\\n\")\n",
    "\n",
    "            # Get breadcrumbs for all source pages used in the context\n",
    "            source_breadcrumbs = []\n",
    "            for url_id in source_ids:\n",
    "                breadcrumb = get_breadcrumb(conn, url_id)\n",
    "                if breadcrumb:\n",
    "                    source_breadcrumbs.append(breadcrumb)\n",
    "\n",
    "            if source_breadcrumbs:\n",
    "                print(\"🔗 Sources:\")\n",
    "                unique_trails = list(dict.fromkeys(source_breadcrumbs))\n",
    "                for trail in unique_trails:\n",
    "                    print(f\"- {trail}\")\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e9c6fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIROH_AIBot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
